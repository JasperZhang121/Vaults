
> Search strategies

Using example from [[0. Exercises 1]]

**State is expanded when it is removed from the frontier, alphabetically removed from queue**

Consider the search space below, where S is the initial state and G1 and G2 both satisfy the goal test. Arcs are labelled with the cost of traversing them and the estimated cost to a goal is reported inside nodes.

![[search.png]]



### BFS
Expanded nodes (layers show in bracket, "/" meaning expanding this node): 
S(0)/, A(1)/, C(1)/, B(2), E(2), D(2), G2(2) => found 

The BFS algorithm finds the shortest path in terms of the number of edges or levels in the graph, not necessarily the shortest path in terms of distance or cost. Therefore, it can be used to find the shortest path in a uniform cost graph where all edges have the same cost, but not in a graph where the edge costs vary.


### DFS
Would simply follow the alphabetical order and ignore the cost for this one when everything same for next two nodes.
Expanded nodes: S(0), A(1), B(2), D(3), <mark style="background: #FF5582A6;">G1(4)</mark>


### Iterative deepening
Expanded nodes:
- 1st: S(0), 
- 2nd: S(0), A(1), C(1), 
- 3rd: S(0), A(1), B(2),E(2), C(1), D(2), G2(2)


### Uniform cost
- Queue: <mark style="background: #FF5582A6;">S(0), A(2), C(2), B(3),D(3), 
G2(6),</mark> G1(7), E(8)
- Expanded: S(0), A(2), C(2), B(3), D(3), G2(6)


### Greedy
- Queue: <mark style="background: #FF5582A6;">S(5), A(2), B(1), G1(0)</mark>, D(1), C(4), E(6)
- Expanded: S(5), A(2), B(1), G1(0)


### A Star
- Queue: <mark style="background: #FF5582A6;">S(5), A(4), B(4), D(5), C(6), D(4), G2(6)</mark>, G1(8), E(16), 
- Expanded nodes: S(0+5=5), A(2+2=4), B(3+1=4), D(4+1=5), C(2+4=6), D(3+1=4), G2(6+0=6)

---

> Various autonomous agents are already in use all around us. Consider a rover on Mars, which is given an instruction to reach a place it can see, and plans a safe route to that location before traversing that path. Based on this description, what type of agent is this Rover?

Based on the description given, the rover on Mars can be classified as a goal-based agent.
A goal-based agent selects its actions based on a desired goal or objective. In the case of the Mars rover, the goal is to reach a specific location that it can see. The agent considers the current state of the environment, but also takes into account the desired outcome or state that it wants to achieve. The agent uses problem-solving algorithms to search through the space of possible actions and plans a sequence of actions that will lead to the desired goal.
In the case of the Mars rover, the agent plans a safe route to the location it can see before traversing that path. This involves considering factors such as terrain, obstacles, and the condition of the rover itself. The agent also needs to take into account the fact that it is operating in a remote and harsh environment, where communication delays and limited resources need to be taken into consideration.


> A* search with the heuristic h(n)=0 for all nodes n will always find an optimal solution.

When the heuristic function h(n) is zero for all nodes, it is an admissible heuristic (and also a consistent heuristic), since it never overestimates the actual cost to reach the goal. A* search uses the heuristic function to guide its search towards the goal node and prioritize nodes that are likely to lead to the optimal solution. Since the heuristic function h(n) always returns a value of 0, A* search will simply explore nodes in the order of their actual cost from the start node, similar to uniform-cost search.

Since the heuristic function h(n) is admissible, A* search will still guarantee to find the optimal solution if one exists, although it may take longer to reach the goal node compared to using a non-zero heuristic function that provides more guidance. Therefore, the statement is true.

Tips:
	<mark style="background: #FF5582A6;">Uniform-cost search (UCS) is a special case of A* search</mark> where the heuristic function is always zero (i.e., h(n) = 0 for all nodes n). Therefore, if the heuristic function h(n) is always zero, both A* search and UCS will behave identically and expand nodes in the order of their actual cost from the start node, guaranteeing to find an optimal solution if one exists.
	In fact, UCS can be seen as a special case of A* search where the weight of the heuristic function is zero (i.e., w = 0 in the weighted A* formula f(n) = g(n) + w*h(n)), which reduces the formula to the actual cost from the start node (i.e., f(n) = g(n) for UCS).


> The big advantage of iterative deepening over depth-first search is its linear space requirements.

Both algorithms have linear space requirements.
In DFS, the space complexity is O(bd), where b is the branching factor and d is the maximum depth of the search tree. This is because DFS stores all the visited nodes on the path from the root to the current node in the stack.
In iterative deepening search, the space complexity is O(bd) as well, but the factor b is smaller. This is because iterative deepening search performs depth-limited search repeatedly, but only needs to store the current path and not the entire tree. The space complexity is dominated by the maximum depth limit, which is d, and not the branching factor.

> When all step costs of the problem are equal, Uniform Cost search is equivalent to Breadth-First search.

Yes, that is correct. When all step costs of a problem are equal, the Uniform Cost search is equivalent to Breadth-First search, as they both explore the nodes in increasing order of path cost. In this case, the only difference between the

> Difference between BFS tree search and BFS graph search?

Breadth-First Tree Search and Breadth-First Graph Search differ in the way they <mark style="background: #FF5582A6;">handle nodes that have already been visited.</mark>
In Breadth-First Tree Search, once a node has been expanded, its successors are <mark style="background: #FF5582A6;">added to the queue even if they have already been visited before</mark>. This means that the algorithm may expand the same node multiple times, leading to redundant computation and increased memory usage.
On the other hand, in Breadth-First Graph Search, when a node is expanded, its successors are only added to the queue if they have not been visited before. <mark style="background: #FF5582A6;">This prevents the algorithm from expanding the same node multiple times, leading to a more efficient and memory-conserving search</mark>.
Therefore, for the same graph, Breadth-First Graph Search will generally expand fewer nodes than Breadth-First Tree Search, making it a more efficient algorithm in terms of both time and space complexity.

> If h1 is an arbitrary consistent heuristic and h2 is an arbitrary consistent heuristic, then (2h1+h2)/3 is necessarily admissible.

The weighted average is always less than or equal to the maximum of h1 and h2, which are both admissible heuristics. Therefore, (2h1 + h2)/3 is also admissible.

> If h1 is an arbitrary admissible heuristic and h2 is an arbitrary consistent heuristic, then  max (h1, h2)  is necessarily admissible

Each heuristic is less than h* so the maximum must be too

> If h1 is an arbitrary admissible heuristic and h2, h3 are arbitrary consistent heuristics, then max(h1, h2) necessarily dominates min(h2, h3).

The maximum of two admissible heuristics is always greater than or equal to each individual heuristic, and the minimum of two consistent heuristics is always less than or equal to each individual heuristic. Therefore, the maximum of h1 and h2 dominates the minimum of h2 and h3.

> If h2 is an arbitrary consistent heuristic, then max(h2 - 1, 0)  is necessarily consistent

True.

If we subtract 1 from a consistent heuristic function h2, we get a new function h3(n) = h2(n) - 1. Since h2 is consistent, it satisfies the triangle inequality: h2(n) ≤ c(n, a, n′) + h2(n′) for every node n and its successor n′ via action a.

Now, let's consider the function h4(n) = max(h2(n) - 1, 0). If h2(n) ≤ 1, then h4(n) = 0, which satisfies the consistency property trivially. Otherwise, h2(n) > 1 and we can write:

h4(n) = h2(n) - 1 ≤ h2(n) - c(n, a, n′) - h2(n′) + h2(n′) - 1 ≤ c(n, a, n′) + (h2(n′) - 1) ≤ c(n, a, n′) + h4(n′)

Thus, we have shown that h4(n) satisfies the consistency property and is therefore a consistent heuristic.

>If h2, h3 are arbitrary consistent heuristics, then (h2+h3)/2 is necessarily consistent.

True.

To prove that the average heuristic (h2+h3)/2 is consistent, we need to show that for any node n, the estimated cost of reaching the goal using this heuristic never overestimates the true cost.

Let's assume that h2(n) and h3(n) are the estimated costs from node n to the goal using h2 and h3 heuristics, respectively. We know that both h2 and h3 are consistent, so:

-   h2(n) ≤ h*(n) + c(n, n') + h2(n'), where n' is any successor of n and c(n, n') is the cost of getting from n to n'
-   h3(n) ≤ h*(n) + c(n, n') + h3(n')

Adding these two inequalities and dividing by 2, we get:

-   (h2(n) + h3(n))/2 ≤ h*(n) + c(n, n') + (h2(n') + h3(n'))/2

This shows that the average heuristic is also consistent, since it satisfies the same inequality as the original heuristics. Therefore, we can conclude that (h2+h3)/2 is necessarily consistent.








