
### PEAS:

To design a rational agent, we must specify the task environment

Consider, e.g., the task of designing a driverless taxi:

• Performance measure: – safety, destination, profits, legality, comfort, … 
• Environment: – streets/freeways, traffic, pedestrians, weather, … 
• Actuators: – steering, accelerator, brake, horn, blinkers, … 
• Sensors: – GPS, video, accelerometers, gauges, engine sensors, …

---

### Properties of Task Environments 

• Fully vs partially observable – do the agent sensors give access to all relevant information about the environment state? 
• Deterministic vs stochastic – is the next state completely determined by the current state and executed action? 
• Known vs unknown – does the agent know the environment’s laws of physics?
• Episodic vs sequential – is the next decision independent of the previous ones? • Static vs dynamic – can the environment change whilst the agent is deliberating? – Semi-dynamic:only the performance score changes. 
• Discrete vs continuous – can time, states, actions, percepts be represented in a discrete way? 
• Single vs multi-agent – is a single agent making decisions, or do multiple agents need to compete or cooperate to maximise interdependent performance measures? 5 Properties of Task Environments

----
### Agent types

- simple reflex agents 
`These agents select actions based solely on the current percept, without considering past percepts or future consequences. They use a set of condition-action rules, known as a rule-based system, to choose the appropriate action. For example, a simple reflex agent might turn on the air conditioning when the temperature exceeds a certain threshold.`

- reflex agents with state
`These agents maintain an internal state, which allows them to take into account past percepts when selecting actions. The internal state is updated based on the current percept and the chosen action. For example, a reflex agent with state might adjust the thermostat based on both the current temperature and whether the air conditioning has been turned on or off in the recent past.`

- goal-based agents 
`These agents select actions based on a desired goal state. They use a problem-solving approach to determine the sequence of actions that will lead to the desired goal state. Goal-based agents can handle complex situations and plan ahead. For example, a goal-based agent might plan a route to a destination by considering the current location, the desired destination, and the available transportation options.`

- utility-based agents
`These agents select actions based on a utility function, which assigns a numerical value to each possible state of the environment. The agent's goal is to maximize the expected utility of its actions. Utility-based agents take into account not only the immediate consequences of their actions but also their long-term effects. For example, a utility-based agent might choose to take a more expensive flight that arrives at a more convenient time, based on the utility it assigns to different combinations of price and convenience.`

---

### Problem solving agents

Form of goal-based agent that formulates the problem of reaching a goal in its environment, searches for a sequence of actions solving the problem, and executes it.

Assumptions about the task environment: 
- fully observable
`A task environment is fully observable if the agent can directly observe the complete state of the environment at each point in time. In such environments, the agent has complete information about the environment and can make decisions accordingly.`

- deterministic
`A task environment is deterministic if the next state of the environment is completely determined by the current state and the agent's actions. In such environments, there is no uncertainty about the consequences of the agent's actions `

- static
`A task environment is static if it does not change while the agent is deliberating. In such environments, the agent can plan its actions in advance without having to worry about unexpected changes in the environment.`

- single agent
`Single Agent: A task environment is single-agent if there is only one agent operating within the environment. In such environments, the agent's actions do not affect the actions of other agents.`

Offline (or open-loop) problem solving is suitable under those assumptions; the entire sequence solution can be executed “eyes closed.”

