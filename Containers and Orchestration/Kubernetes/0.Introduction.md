### Evolution of Application Deployment

#### The Evolution of Deployment Methods

In terms of application deployment, we have seen three major stages:

1. **Traditional Deployment**:
   - **Description**: In the early days of the internet, applications were directly deployed on physical machines.
   - **Advantages**: Simple, no additional technology needed.
   - **Disadvantages**: No clear resource boundaries for applications, making it difficult to allocate resources effectively. Applications could easily affect one another.

2. **Virtualization Deployment**:
   - **Description**: Multiple virtual machines (VMs) could run on a single physical machine, with each VM having its own independent environment.
   - **Advantages**: Application environments do not affect each other, providing enhanced security.
   - **Disadvantages**: Adding an extra operating system layer leads to some resource wastage.

3. **Containerization Deployment**:
   - **Description**: Similar to virtualization, but containers share the host OS.
   - **Advantages**:
     1. Each container has its own file system, CPU, memory, and process space.
     2. Application resources are encapsulated within containers, decoupled from the underlying infrastructure.
     3. Containers can be deployed across different cloud providers and Linux distributions.

#### Issues with Containerization Deployment and Solutions

While containerization offers convenience, it also introduces several challenges:

- How to quickly replace a failed container with a new one?
- How to scale containers horizontally when concurrent access increases?

These issues fall under the category of **container orchestration** problems, which led to the development of container orchestration tools such as:

- **Swarm**: Docker's own orchestration tool.
- **Mesos**: Apache's resource management tool, often used with Marathon.
- **Kubernetes**: Googleâ€™s open-source container orchestration tool.

### Overview of Kubernetes

Kubernetes is a modern, container-based distributed architecture solution. It is the open-source version of Google's Borg system, which was a secret weapon used for over ten years. Kubernetes was first released in September 2014, and the first official stable version was released in July 2015.

At its core, Kubernetes is a cluster of servers that run programs to manage containers on each node. Its primary goal is to automate resource management and provide features such as:

- **Self-healing**: Quickly start a new container within 1 second if one crashes.
- **Elastic scaling**: Automatically adjust the number of running containers as needed.
- **Service discovery**: Services can discover their dependencies automatically.
- **Load balancing**: Requests are automatically distributed across multiple containers if a service has several running containers.
- **Version rollback**: Easily roll back to a previous version if the latest update is problematic.
- **Storage orchestration**: Automatically create storage volumes based on container needs.

### Kubernetes Components

#### Overview of Kubernetes Components

A Kubernetes cluster is mainly composed of **control nodes** (master) and **worker nodes** (node). Each node has different components installed.

- **Control Node (Master)**: The control plane responsible for making decisions for the cluster.
  - **API Server**: The only entry point for cluster operations, it handles user commands, authentication, authorization, API registration, and discovery.
  - **Scheduler**: Responsible for resource scheduling within the cluster, assigning Pods to appropriate nodes based on scheduling strategies.
  - **Controller Manager**: Manages the state of the cluster, including deployment, failure detection, auto-scaling, and rolling updates.
  - **Etcd**: Stores all information about the cluster's resource objects.

- **Worker Node (Node)**: The data plane responsible for providing the runtime environment for containers.
  - **Kubelet**: Manages the lifecycle of containers by interacting with Docker to create, update, or destroy containers.
  - **KubeProxy**: Provides service discovery and load balancing within the cluster.
  - **Docker**: Responsible for handling container operations on the node.

#### Example of Kubernetes Component Interaction

Here's an example using the deployment of an Nginx service to illustrate the interaction between Kubernetes components:

1. Once the Kubernetes environment is up, both the master and nodes store their information in the **etcd** database.
2. An installation request for an Nginx service is first sent to the **API Server** on the master node.
3. The **API Server** then calls the **Scheduler** to decide which node should host the Nginx service. The Scheduler reads the information from **etcd**, applies an algorithm, and reports the chosen node to the API Server.
4. The **API Server** calls the **Controller Manager**, which in turn interacts with the **Node** to install the Nginx service.
5. The **Kubelet** on the chosen node receives the instruction and directs **Docker** to start an Nginx Pod. Pods are the smallest unit of operation in Kubernetes, and containers must run within Pods.
6. The Nginx service is now running. To access Nginx from outside, **KubeProxy** will act as a proxy for external access to the Nginx Pod.

### Kubernetes Concepts

- **Master**: The control node of the cluster. Each cluster must have at least one master node responsible for cluster management.
- **Node**: The worker node where workloads run. The master assigns containers to nodes, and Docker on the node manages the containers.
- **Pod**: The smallest unit in Kubernetes, where containers run. A Pod can contain one or more containers.
- **Controller**: Manages Pods, enabling tasks like starting, stopping, and scaling Pods.
- **Service**: The unified entry point for external access to Pods. It can manage multiple Pods of the same type.
- **Label**: Used for categorizing Pods. Pods of the same type have the same label.
- **Namespace**: Provides an isolated runtime environment for Pods.