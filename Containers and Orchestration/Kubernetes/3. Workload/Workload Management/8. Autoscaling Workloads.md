
Autoscaling enables Kubernetes to automatically adjust resources for workloads, ensuring elastic responses to resource demands.

### Types of Autoscaling

1. **Horizontal Scaling**: Adds or removes pod replicas to meet demand.
2. **Vertical Scaling**: Adjusts CPU and memory resources assigned to containers without adding replicas.

### Manual Scaling

- **Horizontal Scaling**: Use the `kubectl scale` command to set the number of replicas.
- **Vertical Scaling**: Update resource requests and limits by patching workload definitions.

### Automatic Scaling

1. **Horizontal Pod Autoscaler (HPA)**:
   - Scales workload replicas based on CPU or memory usage.
   - Requires **Metrics Server** for monitoring resource usage.
   - Suitable for scaling based on observed resource utilization.

2. **Vertical Pod Autoscaler (VPA)**:
   - Adjusts resource requests of existing pods.
   - Operates in four modes:
     - **Auto**: Assigns resource requests and adjusts them automatically.
     - **Recreate**: Updates requests by evicting and recreating pods.
     - **Initial**: Sets resource requests only on pod creation.
     - **Off**: Calculates recommendations but doesnâ€™t adjust resources automatically.

3. **Cluster Proportional Autoscaler**:
   - Adjusts replica count for system components based on cluster size.
   - **Cluster Proportional Vertical Autoscaler**: Adjusts resources based on the number of nodes or cores.

4. **Event-Driven Autoscaler (KEDA)**:
   - Scales workloads based on event counts (e.g., messages in a queue).
   - Supports a wide range of event sources for dynamic autoscaling.

5. **Scheduled Autoscaling with KEDA**:
   - Allows defining time-based schedules for scaling, useful for managing off-peak hours.

### Scaling Cluster Infrastructure

- **Cluster Autoscaling**: Adjusts node count to maintain required resources, adding nodes during peak demands and removing them during low usage.

