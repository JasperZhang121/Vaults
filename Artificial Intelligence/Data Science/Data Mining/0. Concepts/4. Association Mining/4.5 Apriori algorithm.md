
The _Apriori algorithm_ is the <mark style="background: #FF5582A6;">archetypical algorithm</mark> for finding frequent itemsets.  

It implements an <mark style="background: #FF5582A6;">iterative level-wise search</mark> for frequent itemsets, where  the k-itemsets (itemsets of cardinality _k_) at level _k_ are used to explore the k+1-itemsets at level _k+1._ At each level, the transaction database is scanned to count items in transactions and  to collect the items that satisfy minimum support.

**Apriori Property**

The following observation is used to reduce the search space. This property is very closely related to the  _iceberg condition_ we saw in data cube materialisation.

**All non-empty subsets of a frequent itemset are also frequent**

Recall that a frequent itemset is one with at least  least  _min_sup_ support, i.e. one that occurs in at least _min_sup t_ransactions. Since each of its subsets occur in all those same transactions (and possibly in additional transactions as well),  the support of sub-itemsets cannot be less than _min_sup_ either.

A consequence of this is that **if an itemset is _not_ frequent, then any of its supersets cannot be frequent either** (otherwise the apriori property would be violated).

This can be used in a level-wise algorithm like the _apriori algorithm_ to reduce the search space, because any k+1-itemset with a non-frequent k-itemset subset (all of which have already been found in the previous iteration) can be ignored.

----
### Steps:

1.  Start by scanning the database of transactions to determine the support of each item, i.e., the number of transactions in which it occurs.
2.  Generate a list of frequent <mark style="background: #FF5582A6;">1-itemsets</mark> by selecting those items whose support is greater than or equal to a predefined minimum support threshold.
3.  <mark style="background: #FF5582A6;">Use the frequent 1-itemsets to generate candidate 2-itemsets</mark>, i.e., pairs of items, by joining each frequent itemset with itself.
4.  Scan the database again to determine the support of each candidate 2-itemset and generate a list of frequent 2-itemsets by selecting those whose support is greater than or equal to the minimum support threshold.
5.  Use the frequent <mark style="background: #FF5582A6;">k-itemsets to generate candidate (k+1) itemsets </mark>by joining each frequent itemset with itself.
6.  Repeat steps 4 and 5 until no new frequent itemsets are generated, i.e., <mark style="background: #FF5582A6;">until the list of frequent k-itemsets is empty.</mark>
7.  <mark style="background: #FF5582A6;">Use the frequent itemsets to generate association rules</mark>, i.e., rules of the form A→B, where A and B are disjoint itemsets and the support and confidence of the rule are greater than or equal to predefined minimum thresholds.
