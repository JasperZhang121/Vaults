
#### Lift

In addition to support and confidence which measure association, lift is used to evaluate patterns to measure dependence (also called correlation).

Lift

Inspired by probability theory, itemset $A$ is considered independent of itemset $B$ if $P(A\cup B) = P(A) \times P(B)$. Otherwise they are dependent and correlated.

Therefore we define the lift of rule $A\Longrightarrow B$ by

$$\frac{\text{support}(A\cup B)}{\text{support}(A)\times \text{support}(B)}$$


The numerator is the probability of the customer purchasing both, while the denominator is what the probability of purchasing both would have been if the items were independent.

If $\text{lift} = 1$ then $A$ and $B$ are <mark style="background: #FFF3A3A6;">independent</mark>.

If $\text{lift} > 1$ then they are <mark style="background: #FFF3A3A6;">positively correlated</mark> as the presence of one suggests the presence of the other. In other words, it suggests that each lifts the likelihood of the other.

If $\text{lift} < 1$ the itemsets are <mark style="background: #FFF3A3A6;">negatively correlated</mark> and the occurrence of one itemset suggests the more likely absence of the other.

---

$ACTION:$ But wait, lift is defined above by saying $A$ is independent of $B$ when $P(A\cup B) = P(A) \times P(B)$, while probability theory says that if $A$ and $B$ are independent then $P(A\cap B) = P(A) \times P(B)$. Watch the video if you would like this apparent contradiction explained.

The lift of rule A â†’ B is defined as:

$\text{lift} = \frac{\text{support}(A \cup B)}{\text{support}(A)\times \text{support}(B)}$

Above, we see that A and B are considered independent if:

$P(A\cup B) = P(A) \times P(B)$

However, probability theory tells us that if A and B are independent, then:

$P(A\cap B) = P(A) \times P(B)$

---

Chi-square

For nominal data the correlation between two  (and only two) attributes can be measured by the chi-square test. The chi-square  $(\chi^{2})$ statistic <mark style="background: #FF5582A6;">tests the hypothesis that attributes are independent</mark>. For association rules we treat the itemset on each side of the implication arrow as a single binary attribute each, taking on the value of either all the items are present in the  transaction, or all the items are absent in the transaction. In this way we consider the correlation amongst the complete itemsets of the left and right sides of a rule.

This chi-square test is also called Pearson's chi-square test, not to be confused with Pearson's r that measures correlation  of numerically valued attributes. Both are based on the chi-square distribution.


$$\chi^2 = \sum_{i=1}^{r}\sum_{j=1}^{c} \frac{(O_{ij} - E_{ij})^2}{E_{ij}}$$

Where:

-   $\chi^2$ is the chi-square statistic
-   $O_{ij}$ is the observed frequency in the i-th row and j-th column of the contingency table
-   $E_{ij}$ is the expected frequency in the i-th row and j-th column of the contingency table (under the assumption of independence)
-   $r$ is the number of rows in the contingency table
-   $c$ is the number of columns in the contingency table

The chi-square statistic is used to test the hypothesis of independence between the row variable and the column variable in the contingency table. If the observed frequencies are significantly different from the expected frequencies, we reject the hypothesis of independence and conclude that there is a relationship between the two variables.

The degree of freedom for the chi-square test is (r-1)*(c-1), where r is the number of rows in the contingency table and c is the number of columns.


The degrees of freedom for the chi-square test is given by:

<mark style="background: #FFF3A3A6;">df = (n-1) * (m-1)</mark>

<mark style="background: #FF5582A6;">We reject the null hypothesis and conclude that there is a significant association between the items if the chi-square value is greater than the critical value at a given level of significance and the degrees of freedom.</mark>

---

The chi-square test for non-singleton itemsets measures the degree of association between two or more items in a transaction. The null hypothesis is that the items are independent, while the alternative hypothesis is that there is a significant association between them.

To calculate the chi-square value, we use the following formula:

$\chi^{2} = \sum_{i=1}^{n} \sum_{j=1}^{m} \frac{(O_{ij} - E_{ij})^2}{E_{ij}}$

where:

-   $\chi^{2}$ is the chi-square value
-   n is the number of rows in the contingency table
-   m is the number of columns in the contingency table
-   $O_{ij}$ is the observed frequency in the contingency table for the ith row and jth column
-   $E_{ij}$ is the expected frequency in the contingency table for the ith row and jth column, calculated as (row total * column total) / grand total

