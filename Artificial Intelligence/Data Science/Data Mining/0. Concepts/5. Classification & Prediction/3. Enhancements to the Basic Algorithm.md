
Handle missing attribute values
- Assign the <mark style="background: #D2B3FFA6;">most common value</mark> of the attribute
- Assign <mark style="background: #ABF7F7A6;">probability</mark> to each of the possible values

Attribute construction
- Create new attributes based on existing ones that are sparsely represented
- This reduces fragmentation, repetition, and replication

Continuous target variable
- In this case the tree is called a _regression tree_, the leaf node classes are represented by their mean values, and  the tree performs <mark style="background: #FFF3A3A6;">prediction</mark> (using that mean value) rather than classification.

Probabilistic classifier
- Instead of majority voting to assign a class label to a leaf node, the _proportion_ of training data objects of each class in the leaf node can be interpreted to as the _probability_ of the class, and this probability can be assigned to the classification  for unknown objects falling in that node at use-time.

---

### Extracting rules from decision trees
- A useful process for understanding the decision-making process and explaining the results to stakeholders. 
- A decision tree can be <mark style="background: #FFB86CA6;">transformed into a set of if-then rules</mark>, which can be used to classify new data. 
- The rules can also be analyzed to identify patterns and gain insights into the data.

### Process of rule extraction 
- Traversing the decision tree <mark style="background: #CACFD9A6;">from the root node to the leaf nodes and creating rules for each path</mark>. 
- The rule for each path is created by combining the conditions along the path to form an if-then statement.
- The <mark style="background: #ADCCFFA6;">condition of each internal node is combined using the logical AND operator</mark>, while the condition at the leaf node is used as the output or decision.

The rules can be simplified by <mark style="background: #BBFABBA6;">removing redundant conditions and combining similar rules</mark>. This process is called rule pruning and can be performed manually or using algorithms. The resulting rules can be expressed in a human-readable format and used to explain the decision-making process to stakeholders

### Properties of extracted rules
-   Mutually exclusive
    -   We <mark style="background: #D2B3FFA6;">cannot have rule conflicts</mark> here because no two rules will be triggered for the same tuple.
    -   We have <mark style="background: #CACFD9A6;">one rule per leaf</mark>, and any tuple can map to only one leaf.
-   Exhaustive:
	-   There is one rule for each possible attribute–value combination, so that this set of rules does not require a default rule.
	-   The order of rules is irrelevant.

