### Data mining often uses information about individual people.

-   People often feel that this information is <mark style="background: #FF5582A6;">private</mark> to themselves, and only the person in question has the right to decide who to share it with, and for what purpose.
-   People often <mark style="background: #FFB8EBA6;">willingly or unconsciously but consentingly share</mark> such private information.
-   The information may be shared for reasons quite independently of data mining, but it may be mined for _secondary use._
-   e.g. credit card transactions, health records, personal financial records, individual biological traits, criminal or justice investigations, ethnicity, educational performance.

Not all data mining uses personal data, although it may nevertheless be _confidential_ data.

-   e.g. natural resources, climate and weather, water storage and floods, astronomy, geography, geology, biology
-   other scientific and engineering data

Access to individual records directly attributable to individual people is the most common source of concern. This data may leak in ways that have no connection to data mining (e.g Web shopping). Nevertheless, when it is collected initially for the purposes of mining, or when mining is a secondary use, the data miner should be aware of their legal and ethical obligations to protect privacy.

----

### What is fair use of the private data?  


The <mark style="background: #FF5582A6;">OECD (Organisation for Economic Cooperation)</mark>, of which Australia is a member, It  provides some useful _principles_ for personal data, summarised here:  

-   **Collection Limitation**: Data should be <mark style="background: #FFB86CA6;">collected by lawful and fair means</mark>, with the knowledge and consent of the individual where appropriate.
-   **Data Quality**: For the purpose that data is used, it should be <mark style="background: #ABF7F7A6;">relevant, accurate, complete and up-to-date</mark>.
-   **Purpose Specification:** Data should be collected <mark style="background: #D2B3FFA6;">only for a specified purpose</mark>, and used for that purpose (although alternative uses are conditionally possible).
-   **Use Limitation**: Data should <mark style="background: #CACFD9A6;">not be disclosed or used for other purposes unless authorised by the person or by the law</mark>.
-   **Security Safeguards**: Data should be protected by reasonable security safeguards.
-   **Openness Principle**:  Developments, practices and policies with respect to data should be open, including the existence and nature of data, the main purposes of use, and the identity and contact method for a data controller.
-   **Individual Participation**: Individuals have the right to obtain confirmation of existence or absence of data relating to them, to obtain such data, to challenge such data, and if successful,  to have the data erased, rectified, completed or amended.
-   **Accountability Principle**: A data controller is accountable for complying with the principles.

### How to protect privacy when data mining?

Careless disclosure control by data miners can be the cause of privacy breaches. Private data should be managed securely, and <mark style="background: #FF5582A6;">privacy-preserving data mining can be used to ensure that the results of data mining can be shared without sharing personal data</mark>.

**Data-security enhancing techniques** include

-   **Multilevel security model in databases** - users are<mark style="background: #FFB86CA6;"> authorised to access only data that is classified at their security level</mark>. Although can permit an inference of hidden data.
-   **Encryption** - personal data may be <mark style="background: #BBFABBA6;">encrypted and protected by signatures, biometrics, locational distribution</mark>.
-   **Intrusion detection** - actively monitor for breaches
-   **Physical access control -** keep the data off-network and <mark style="background: #ADCCFFA6;">secured in a physical space</mark>.

**Privacy-preserving data mining techniques** include

-   **Randomization methods (a.k.a perturbation) -** where <mark style="background: #CACFD9A6;">noise is added to the data</mark> (i.e .errors are introduced), that are sufficiently large to hide the genuine values, but so that the final results of data mining will be preserved -e.g. aggregate distributions are preserved.
-   **_K_-anonymity methods** - where the <mark style="background: #BBFABBA6;">granularity of data is reduced</mark> so that at least _k_ individuals share the same identifying attributes so no individual can be uniquely recognised (e.g. grouping street address to postcode so that at least k individuals have the same postcode).
-   **_L-_diversity methods**  - where granularity is reduced as for _K_-anonymity but <mark style="background: #FFB8EBA6;">additionally values for particularly sensitive information within a group are required to be diverse</mark>  (e.g. _all_ salary brackets should be represented in the group with the same postcode).
-   **Federated analytics**  - large data sets are partitioned into subsets that are mined independently but limited information sharing of data mining results can assure individual privacy while enabling aggregate results.
-   **Downgrading results** - Hide some of the results like association rules or clusters that apply to only  small numbers of individuals.
-   **Differential Privacy** - use algorithms that are formally guaranteed to give approximately the same results on data sets that differ in only a small number of records, so that the presence of absence of an individual's data does not affect the result significantly.
-   **Statistical Disclosure Control -** implement governance procedures that ensure sensitive information is not released.