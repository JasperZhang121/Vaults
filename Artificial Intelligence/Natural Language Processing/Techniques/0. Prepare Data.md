```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder

def prepare_dataset(filename):
    """
    Prepare the training/validation/test dataset.

    Args:
        filename (str): The name of the file from which data will be loaded.

    Returns:
        Xr_train (list[str]): Documents in the training set, each represented as a string.
        y_train (np.ndarray): A vector of class labels for documents in the training set, each element of the vector is either 0 or 1.
        Xr_val (list[str]): Documents in the validation set, each represented as a string.
        y_val (np.ndarray): A vector of class labels for documents in the validation set, each element of the vector is either 0 or 1.
        Xr_test (list[str]): Documents in the test set, each represented as a string.
        y_test (np.ndarray): A vector of class labels for documents in the test set, each element of the vector is either 0 or 1.
    """
    print('Preparing train/val/test dataset ...')
    
    # Load raw data
    df = pd.read_csv(filename)
    
    # Shuffle the rows
    df = df.sample(frac=1, random_state=123).reset_index(drop=True)
    
    # Get the train, val, test splits
    train_frac, val_frac, test_frac = 0.7, 0.1, 0.2
    Xr = df["text"].tolist()
    train_end = int(train_frac * len(Xr))
    val_end = int((train_frac + val_frac) * len(Xr))
    Xr_train = Xr[:train_end]
    Xr_val = Xr[train_end:val_end]
    Xr_test = Xr[val_end:]

    # Encode sentiment labels ('pos' and 'neg')
    yr = df["label"].tolist()
    le = LabelEncoder()
    y = le.fit_transform(yr)
    y_train = np.array(y[:train_end])
    y_val = np.array(y[train_end:val_end])
    y_test = np.array(y[val_end:])
    
    return Xr_train, y_train, Xr_val, y_val, Xr_test, y_test
```