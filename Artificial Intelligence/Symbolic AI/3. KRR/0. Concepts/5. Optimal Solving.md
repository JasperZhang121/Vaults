
Optimal solving in constraint satisfaction problems (CSPs) involves finding solutions that are optimal with respect to a given objective function. This is often useful in practical applications where there may be multiple solutions to a problem, but some solutions are better than others based on certain criteria.

One approach to optimal solving in CSPs is to use complete search algorithms that systematically search the entire solution space for the optimal solution. These algorithms can be very effective for small problem instances, but they can become <mark style="background: #FFB8EBA6;">computationally infeasible for larger problems</mark> due to the exponential growth in the number of possible solutions.

Another approach is to use heuristic search algorithms that use <mark style="background: #BBFABBA6;">heuristics to guide the search towards the most promising solutions</mark>. These algorithms can be faster than complete search algorithms for larger problems, but they may not guarantee finding the optimal solution.

Optimal solving in CSPs can also be done using optimization techniques such as linear programming or mixed-integer programming. These techniques formulate the CSP as an optimization problem and use optimization solvers to find the optimal solution. These techniques can be very powerful for large-scale problems, but they may require significant computational resources and may not be applicable to all types of CSPs.

Symmetry breaking techniques can also be useful in optimal solving. Symmetry in CSPs can cause redundant computations and can make it difficult to find the optimal solution. By breaking symmetry, the search space can be reduced, and the search can be directed towards the most promising solutions.


----

### Depth-First Branch and Bound

A search algorithm used in optimization problems to find the optimal solution by<mark style="background: #BBFABBA6;"> incrementally searching the solution space</mark> while <mark style="background: #ADCCFFA6;">keeping track of the best solution found so far</mark>. The algorithm uses a depth-first search strategy to explore the solution space, and employs a branch and bound technique to prune the search tree and eliminate suboptimal solutions.

In the DFBB algorithm, the search begins at the root of the tree, and moves recursively down the tree, expanding nodes and branching out to explore new solutions. At each node, the algorithm computes the lower bound of the solution, which is an estimate of the <mark style="background: #FFB8EBA6;">minimum possible</mark> value of the objective function. If the lower bound is greater than the best solution found so far, the node is pruned and the search moves on to the next node. If the lower bound is less than or equal to the best solution found so far, the node is expanded and the search continues down the tree.

The DFBB algorithm maintains <mark style="background: #FFF3A3A6;">a global best solution</mark> throughout the search, and updates it whenever a new better solution is found. The algorithm terminates when all nodes have been explored or when the best solution found cannot be improved further.

### Pseudocode

```python
Procedure DFBranchAndBound(G,s,goal,h,bound0)

    Inputs:
        G: graph with nodes N and arcs A
        s: start node
        goal: Boolean function on nodes
        h: heuristic function on nodes
        bound0: initial depth bound (can be ∞ if not specified)
        
    Output:
        a least-cost path from s to a goal node if there is a solution with cost less than bound0
        or ⊥ if there is no solution with cost less than bound0
        
    Local:
        best_path: path or ⊥
        bound: non-negative real
    
    Procedure cbsearch(⟨n0,...,nk⟩)
        if (cost(⟨n0,...,nk⟩)+h(nk) < bound) then
            if (goal(nk)) then
                best_path ←⟨n0,...,nk⟩
                bound ←cost(⟨n0,...,nk⟩)
            else
                for each arc ⟨nk,n⟩∈A do
                    cbsearch(⟨n0,...,nk,n⟩)
    best_path ←⊥
    bound ←bound0
    cbsearch(⟨s⟩)
    return best_path
```


---

## Local Search 

is a family of algorithms that iteratively improves a candidate solution by making small incremental changes. The basic idea is to start with some initial solution, then repeatedly make small changes to it to see if any of the resulting solutions are better. Local search algorithms can be useful when the search space is too large to exhaustively search, and when it is easy to evaluate the quality of a solution.

One example of a local search algorithm is <mark style="background: #ABF7F7A6;">hill climbing</mark> (gradient ascent/descent). In hill climbing, the algorithm starts with some initial solution, then repeatedly makes small changes to it by considering nearby solutions. At each step, the algorithm selects the neighboring solution that gives the best improvement in the objective function. This process continues until a local optimum is reached, i.e., a solution where no nearby solution is better.

![[Hill_Climbing.png]]

In the context of Constraint Satisfaction Problems (CSP), local search is a method for finding a solution to the problem by iteratively i<mark style="background: #FFB8EBA6;">mproving a partial assignment of values to variables</mark>. The idea is to start with a random or initial assignment, and then search for better assignments by modifying the current assignment in small steps.

The local search algorithm repeatedly chooses a variable and assigns a new value to that variable, based on a heuristic function that evaluates how good the new assignment (such as changing assginments to the most constrainted varible) is. The algorithm <mark style="background: #D2B3FFA6;">continues until no further improvements can be made</mark>, or until a predefined stopping condition is met (such as a maximum number of iterations or time limit).

Local search can be useful for solving CSPs that are too large or complex to be solved using exact methods like backtracking. However, it is <mark style="background: #CACFD9A6;">not guaranteed to find the global optimum</mark>, and can get stuck in local optima. Therefore, it is often used in combination with other methods like simulated annealing or genetic algorithms to avoid being trapped in local optima.

#### Pseudocode

```python
function Hill-Climbing(problem) returns a state that is a local maximum

inputs:
    problem, a problem

local variables:
    current, a node
    neighbour, a node

current ← Make-Node(Initial-State[problem])

loop do
    neighbour ← a highest-valued successor of current
    if Value[neighbour] ≤ Value[current] then return State[current]
    current ← neighbour
end
```


### Simulated annealing 

A popular heuristic method for optimization problems, including CSPs. It is a type of local search that allows the algorithm to <mark style="background: #FFF3A3A6;">escape from local optima</mark> and explore a wider search space.

In simulated annealing, the algorithm starts with an initial solution, which is then iteratively refined by making small changes to the current solution. At each iteration, a neighbor solution is generated by randomly perturbing the current solution, and the algorithm evaluates the quality of the neighbor solution using an objective function. If the neighbor solution is better than the current solution, it is accepted as the new current solution. However, if the neighbor solution is worse, it may still be accepted with a certain probability that decreases over time. This probability is controlled by a parameter called the temperature, which is gradually reduced during the search.

The intuition behind simulated annealing is that, at the beginning of the search, the algorithm can accept worse solutions with a higher probability, allowing it to explore a wider search space and potentially find better solutions. As the search progresses and the temperature decreases, the algorithm becomes more selective and focuses on refining the best solutions found so far.

Simulated annealing can be applied to CSPs by defining an objective function that measures the quality of a solution. The objective function can be based on the number of violated constraints, the amount of unsatisfied constraints, or other factors related to the problem domain. By using simulated annealing to search for solutions that optimize the objective function, the algorithm can find high-quality solutions to CSPs.


```python
function Simulated-Annealing(problem, schedule) returns a solution state
    inputs: problem, a problem
            schedule, a mapping from time to “temperature”
    local variables: current, a node
                     neighbour, a node
                     T, a “temperature” controlling prob. of downward steps
    current ←Make-Node(Initial-State[problem])
    for t ← 1 to ∞ do
        T ← schedule[t]
        if T = 0 then return current
        neighbour ← a randomly selected successor of current
        ∆E ← Value[neighbour] – Value[current]
        if ∆E > 0 then 
            current ← neighbour
        else 
            current ← neighbour only with probability e∆E/T
    end
end
```


### Population-based methods 

- <mark style="background: #FFB8EBA6;">Local beam search</mark> maintains a population of k states, adds some neighbors at each step, and deletes the worst ones to keep the population stable. There are many variants of this method. 
- On the other hand, <mark style="background: #ABF7F7A6;">genetic or evolutionary algorithms</mark> define "crossover" between pairs of states in the population, where the offspring have some features of each parent. The culling process is then based on a "fitness" measure. This approach has been extensively researched over several decades, and there are many variations on the general method.


### Large Neighbourhood Search (LNS) 

A metaheuristic optimization technique for solving constraint satisfaction problems (CSPs). The technique was first proposed in the early 2000s as an alternative to standard local search and hill-climbing algorithms, which can get stuck in local optima. LNS combines local search with a perturbation strategy that allows it to jump out of local optima and explore new regions of the search space.

The basic idea behind LNS is to <mark style="background: #BBFABBA6;">break the current solution into pieces</mark>, modify one or more of these pieces, and then <mark style="background: #ABF7F7A6;">try to repair the solution by using local search</mark>. The pieces are typically chosen based on some heuristic that identifies parts of the solution that are the most constrained or difficult to satisfy. The perturbation strategy can be designed in a number of ways, such as by randomly modifying some subset of the variables or by selecting a small number of constraints to remove and then adding them back one at a time.

One of the main advantages of LNS is that it can <mark style="background: #CACFD9A6;">be customized to fit the specific characteristics of a given problem</mark>. For example, the perturbation strategy can be tailored to the nature of the constraints or to the distribution of variable values in the search space. This flexibility allows LNS to be applied to a wide range of CSPs, including those with highly nonlinear constraints or with large numbers of variables.

LNS has been shown to be effective in solving many real-world problems, such as scheduling, routing, and logistics. In some cases, it has been able to find optimal solutions or solutions that are close to optimal in a short amount of time. LNS can also be combined with other metaheuristic techniques, such as genetic algorithms or tabu search, to further improve its performance.

Like other metaheuristic techniques, LNS has some limitations. One of the main challenges is in finding an <mark style="background: #ADCCFFA6;">appropriate balance between exploration and exploitation of the search space</mark>. If the perturbation strategy is too aggressive, it may be difficult to repair the solution using local search. On the other hand, if the perturbation strategy is too conservative, the search may get stuck in local optima. Another challenge is in choosing an appropriate stopping criterion, since LNS may continue to improve the solution even after a certain number of iterations or time limit has been reached.