
## State-space planning


### Forward Search (sound and complete)

Forward search is a simple and intuitive planning algorithm. It starts with the initial state and <mark style="background: #FFB8EBA6;">generates successor states by applying available actions</mark>. If a successor state is a goal state, the planning process terminates. Otherwise, the algorithm continues the search from the successor state.
```python
```python
from collections import deque

def forward_search(problem):
    frontier = deque()
    explored = set()

    # Create a node with the initial state and add it to the frontier
    start_node = Node(problem.initial_state, None, None)
    frontier.append(start_node)

    while frontier:
        current_node = frontier.popleft()

        # Check if the current state is a goal state
        if problem.is_goal_state(current_node.state):
            return construct_plan(current_node)

        explored.add(current_node.state)

        # Generate the next possible actions
        actions = problem.get_actions(current_node.state)

        for action in actions:
            next_state = problem.apply_action(current_node.state, action)

            # Create a new node for the next state
            next_node = Node(next_state, current_node, action)

            # Add the next node to the frontier if it hasn't been explored before
            if next_state not in explored:
                frontier.append(next_node)

    return None  # No valid plan found


def construct_plan(node):
    plan = []
    while node.parent is not None:
        plan.append(node.action)
        node = node.parent
    plan.reverse()
    return plan
```

#### Problems:

- domain-specific: search control rules, heuristics
- domain-independent: heuristics extracted from the STRIPS problem description 
- backward search: from the goal to the initial state

### Backward Search

Backward search is a planning algorithm that starts with the goal state and works backward to the initial state. It generates predecessor states by applying available actions and checks if the predecessor state is the initial state. If it is, the planning process terminates. Otherwise, the algorithm continues the search from the predecessor state.

### Heuristic Search

Heuristic search algorithms, such as A* and IDA*, use heuristic functions to guide the search process. The heuristic function estimates the cost of reaching a goal state from a given state. The search algorithm then chooses the state with the lowest estimated cost and expands it.

### Graphplan

Graphplan is a classical planning algorithm that uses a propositional logic representation of the planning problem. It constructs a planning graph that represents the set of all possible states and actions in the planning problem. The planning graph is then used to find a valid plan.

```python
class GraphPlanner(object):

    def __init__(self):
        self._layered_plan: LayeredPlan = LayeredPlan()
        self._mutex = {}
       
    def plan(self, gr: Graph, g: set):
        index = gr.num_of_levels - 1

        if not g.issubset(gr.prop[index]):
            return None

        plan = self._extract(gr, g, index)
        if plan:
            return self._layered_plan

        if gr.fixed_point:
            n = 0
            try:
                props_mutex = self._mutex[gr.num_of_levels - 1]
            except KeyError:
                props_mutex = None
            if props_mutex:
                n = len(props_mutex)
        else:
            n = 0

        while True:
            index += 1
            gr = PlanningGraph.expand(gr)
            plan = self._extract(gr, g, index)
            if plan:
                return self._layered_plan
            elif gr.fixed_point:
                try:
                    props_mutex = self._mutex[gr.num_of_levels-1]
                except KeyError:
                    props_mutex = None
                if props_mutex:
                    if n == len(props_mutex):
                        # this means that it has stabilised
                        return None
                    else:
                        n = len(props_mutex)
```

#### Plan Extraction

```python
function Extract(i, gi, πi) returns a parallel plan, or failure
    if i = 0 then return πi
    
    if gi ≠ {} then
        select any p ∈ gi
        E ← {a ∈ Ai | p ∈ eff+(a) and ∀b ∈ πi {(a, b)} ∉ µAi}
        if E = {} then return failure
        
        for each a ∈ E do
            result ← Extract(i, gi \ eff+(a), πi ∪ {a})
            if result ≠ failure then
                return result
        
        return failure
    else
        π ← Extract(i - 1, ∪a ∈ πi Pre(a), {})
        if π = failure then return failure
        
        return π.πi
end

call: Extract(k, g, {}) where k is the last layer in the graph
```

------------

### STRIPS

STRIPS (Stanford Research Institute Problem Solver) is a language and planning system for describing and solving problems in artificial intelligence. It was developed at SRI International in the 1960s and was one of the first automated planning systems.

The STRIPS language consists of a set of <mark style="background: #BBFABBA6;">states, actions, and initial and goal states</mark>. The actions describe how the states can be changed, and the initial and goal states describe the starting and ending points of the problem. The actions are specified in terms of preconditions, which must be true for the action to be performed, and effects, which describe the changes that occur to the states when the action is performed.

STRIPS uses a forward-chaining inference algorithm to search for a plan that will take the system from the initial state to the goal state. The algorithm builds a search tree of possible plans, starting with the initial state and working forward through the actions until it reaches the goal state.


### PDDL

PDDL stands for "Planning Domain Definition Language". It is<mark style="background: #ABF7F7A6;"> a formal language used to describe planning problems and domains in artificial intelligence</mark>. PDDL was created to standardize the representation of planning problems and solutions, making it easier to share and compare different planning algorithms.

PDDL is a declarative language, meaning that it describes the problem in terms of its <mark style="background: #FF5582A6;">properties and constraints</mark>, rather than specifying a set of steps to solve the problem. The language provides a way to define the initial state of a problem, the set of possible actions, and the goal state.

PDDL is commonly used in AI research and development, and many planning systems and solvers are designed to work with PDDL. The language has evolved over time, with new versions adding additional features and capabilities to better represent more complex planning problems.

#### Syntax

The syntax of PDDL consists of a set of rules that define the elements of the planning problem, such as the objects, initial state, goal state, and actions. Here is a brief overview of the syntax:

-   Objects: declared using the `:objects` keyword followed by a list of object names enclosed in parentheses.
    
-   Predicates: declared using the `:predicates` keyword followed by a list of predicate names and their arguments enclosed in parentheses.
    
-   Initial state: declared using the `:init` keyword followed by a list of ground literals that describe the initial state of the planning problem.
    
-   Goal state: declared using the `:goal` keyword followed by a list of ground literals that describe the desired goal state of the planning problem.
    
-   Actions: declared using the `:action` keyword followed by the name of the action, a list of its parameters enclosed in parentheses, a list of its preconditions enclosed in parentheses after the keyword `:precondition`, and a list of its effects enclosed in parentheses after the keyword `:effect`.
    

The preconditions and effects of an action are defined in terms of predicates and literals that refer to objects and their states. The syntax of PDDL also includes several other keywords and constructs, such as types, functions, and axioms, which provide additional expressivity for specifying planning problems.

#### Example

```ruby
(define (domain blocks)
  (:requirements :strips)
  (:predicates 
    (on ?x - block ?y - block)
    (ontable ?x - block)
    (clear ?x - block)
    (holding ?x - block))
  (:action pick-up
    :parameters (?x - block)
    :precondition (and (clear ?x) (ontable ?x) (not (holding ?x)))
    :effect (and (not (ontable ?x)) (not (clear ?x)) (holding ?x)))
  (:action put-down
    :parameters (?x - block)
    :precondition (holding ?x)
    :effect (and (ontable ?x) (clear ?x) (not (holding ?x))))
  (:action stack
    :parameters (?x - block ?y - block)
    :precondition (and (holding ?x) (clear ?y))
    :effect (and (not (holding ?x)) (not (clear ?y)) (on ?x ?y) (clear ?x)))
  (:action unstack
    :parameters (?x - block ?y - block)
    :precondition (and (on ?x ?y) (clear ?x) (not (holding ?x)))
    :effect (and (holding ?x) (clear ?y) (not (on ?x ?y)))))
```

```ruby
(define (problem blocks-4-0)
  (:domain blocks)
  (:objects a b c d - block)
  (:init 
    (on a b) (on b c) (ontable c) (ontable d) (clear a) (clear d)
    (not (on a c)) (not (on b d)) (not (holding ?x)))
  (:goal (and (on a b) (on b c) (on c d))))
```


### ADL
Action Description Language, which is a formal language used to specify actions and their effects in AI planning. ADL is an <mark style="background: #FFB8EBA6;">extension of STRIPS</mark> (Stanford Research Institute Problem Solver) language and allows the representation of more complex actions with richer preconditions and effects.

ADL representation includes several features such as conditional effects, negative preconditions, quantified preconditions, and disjunctive preconditions. Conditional effects enable the specification of effects that are dependent on the conditions of the action. Negative preconditions allow stating what must not hold true for an action to be applicable. Quantified preconditions and disjunctive preconditions enable the specification of a range of values for the preconditions.

The ADL representation is used by many AI planning systems, including SHOP and C+ +, and provides a more expressive and flexible way of describing actions and their effects, making it easier to develop complex planning problems.

### Graphplan

A planning algorithm that was introduced by Avrim Blum and Merrick Furst in 1995. The algorithm works by constructing a planning graph, which is a bipartite directed graph that represents the state space of the planning problem. The nodes in the graph represent the propositions that are true in a given state, and the edges represent the actions that can be taken to change the state.

Graphplan works by constructing the planning graph in layers, where each layer contains all of the propositions and actions that can be achieved from the propositions in the previous layer. This process continues until either a goal state is found or a fixed number of layers have been constructed without finding a solution.

Once the planning graph has been constructed, Graphplan uses a <mark style="background: #FFB8EBA6;">backward search</mark> to find a plan that achieves the goal state. This search works by starting at the goal state and working backwards through the layers of the planning graph to the initial state, using a series of graph-based operations to construct a plan.

Graphplan has been shown to be more efficient than previous planning algorithms in many cases, particularly in problems where the state space is large and the goals are complex. However, it has also been criticized for being too computationally expensive in some cases, and for not being able to handle some types of planning problems.


### Mutual exclusion
A concept in Graphplan that is used to <mark style="background: #FFF3A3A6;">prevent multiple actions from executing on the same set of literals simultaneously</mark>. In other words, it ensures that no two actions that change the same set of literals can occur at the same time.

This concept is achieved in Graphplan through the use of mutexes (short for mutual exclusions). A mutex is a binary relation between two actions that indicates that they cannot both be executed in any valid plan. Mutexes are computed as part of the Graphplan algorithm, and they are derived from the preconditions and effects of the actions.

For example, consider the two actions "drive to airport" and "drive to hotel". These two actions are mutex because they both require the robot to be in the same location (i.e., in the car), but they have different goals (i.e., airport vs. hotel). Thus, these actions cannot both occur in the same plan.

Mutexes can be used to <mark style="background: #FFB8EBA6;">prune the search space of possible plans and reduce the amount of search that must be done.</mark> By identifying mutexes, Graphplan can eliminate certain combinations of actions that are guaranteed to be invalid, and focus on finding valid plans instead.