
### PEAS:

To design <mark style="background: #FF5582A6;">a rational agent</mark>, we must specify the <mark style="background: #FFF3A3A6;">task environment</mark>

-   Performance measure: the criterion for success in the agent's task
-   Environment: the external context in which the agent operates
-   Actuators: the output devices through which the agent interacts with the environment
-   Sensors: the input devices through which the agent perceives the environment

---

### Properties of Task Environments 

• <mark style="background: #FFB8EBA6;">Fully vs partially observable</mark> – do the agent sensors give access to all relevant information about the environment state? 
• <mark style="background: #FFF3A3A6;">Deterministic vs stochastic</mark> – is the next state completely determined by the current state and executed action? 
• Known vs unknown – does the agent know the environment’s laws of physics?
• <mark style="background: #ADCCFFA6;">Episodic vs sequential</mark> – is the next decision independent of the previous ones? • Static vs dynamic – can the environment change whilst the agent is deliberating? – Semi-dynamic:only the performance score changes. 
• Discrete vs continuous – can time, states, actions, percepts be represented in a discrete way? 
• <mark style="background: #CACFD9A6;">Single vs multi-agent</mark> – is a single agent making decisions, or do multiple agents need to compete or cooperate to maximise interdependent performance measures? 5 Properties of Task Environments

----
### Agent types

- Simple reflex agents 
	These agents select actions based <mark style="background: #FF5582A6;">solely on the current percept</mark>, without considering past percepts or future consequences. They use a set of condition-action rules, known as a <mark style="background: #FFF3A3A6;">rule-based system</mark>, to choose the appropriate action. For example, a simple reflex agent might turn on the air conditioning when the temperature exceeds a certain threshold.

- Reflex agents with state
	These agents maintain an <mark style="background: #FF5582A6;">internal state</mark>, which allows them to take into account <mark style="background: #FF5582A6;">past percepts</mark> when selecting actions. The <mark style="background: #CACFD9A6;">internal state is updated based on the current percept and the chosen action</mark>. For example, a reflex agent with state might adjust the thermostat based on both the current temperature and whether the air conditioning has been turned on or off in the recent past.

- Goal-based agents 
	These agents select actions based on a desired <mark style="background: #FF5582A6;">goal state</mark>. They use a problem-solving approach to determine the sequence of actions that will lead to the desired goal state. Goal-based agents can handle complex situations and plan ahead. For example, a goal-based agent might plan a route to a destination by considering the current location, the desired destination, and the available transportation options.

- Utility-based agents
	These agents select actions based on <mark style="background: #FF5582A6;">a utility function</mark>, which assigns a numerical value to each possible state of the environment. The agent's goal is to maximize the expected utility of its actions. Utility-based agents take into account not only the <mark style="background: #FFF3A3A6;">immediate</mark> consequences of their actions but also their long-term effects. For example, a utility-based agent might choose to take a more expensive flight that arrives at a more convenient time, based on the utility it assigns to different combinations of price and convenience.

---

### Problem solving agents

Form of goal-based agent that formulates the problem of reaching a goal in its environment, searches for a sequence of actions solving the problem, and executes it.

Assumptions about the task environment: 
- fully observable
	A task environment is fully observable if the agent can directly observe the complete state of the environment at each point in time. In such environments, the agent has <mark style="background: #FFB8EBA6;">complete information</mark> about the environment and can make decisions accordingly.

- deterministic
	A task environment is deterministic if the <mark style="background: #FF5582A6;">next state of the environment is completely determined by the current state</mark> and the agent's actions. In such environments, there is no uncertainty about the consequences of the agent's actions 

- static
	A task environment is static if it <mark style="background: #FF5582A6;">does not change while the agent is deliberating</mark>. In such environments, the agent can plan its actions in advance without having to worry about unexpected changes in the environment.

- single agent
	Single Agent: A task environment is single-agent if there is only <mark style="background: #FF5582A6;">one agent</mark> operating within the environment. In such environments, the agent's actions do not affect the actions of other agents.

Offline (or open-loop) problem solving is suitable under those assumptions; the entire sequence solution can be executed “eyes closed.”

