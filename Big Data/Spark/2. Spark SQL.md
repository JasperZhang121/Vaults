## Introduction

Spark SQL is a Spark module for structured data processing. It provides a programming interface for data frames and can also act as a distributed SQL query engine.

## Features

1. **Integrated with Big Data Tools:** Can read from other sources like Hadoop, Apache Cassandra, Apache HBase, and more.
2. **Performance:** Uses Catalyst Optimizer for query optimization, leading to faster results.
3. **Connectivity:** Can connect with BI tools via JDBC/ODBC connectors.

## Basic Usage

### Starting a SparkSession

```python
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("SparkSQL").getOrCreate()
```

### Reading Data

```css
df = spark.read.json("path_to_json_file.json")
```

### DataFrame Operations

```css
df.show()
df.printSchema()
df.select("column_name").show()
```

### SQL Queries

To run SQL queries directly on files:

```css
spark.sql("SELECT * FROM parquet.`path_to_parquet_file.parquet`")
```

To run SQL queries on DataFrames, first register the DataFrame as a temporary view:

```css
df.createOrReplaceTempView("table_name")
results = spark.sql("SELECT * FROM table_name")
```

