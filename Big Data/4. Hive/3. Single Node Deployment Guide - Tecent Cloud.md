
### 1. Setup Hadoop

(this part same as [[7. Single Node Deployment Guide - Tecent Cloud]] in Hadoop)
#### Create a Hadoop User
```bash
sudo adduser hadoop
sudo passwd hadoop
sudo usermod -aG sudo hadoop
sudo usermod -aG wheel hadoop
su - hadoop
```

#### Install Java
```bash
sudo yum install java-1.8.0-openjdk-devel
```

#### Download and Install Hadoop
- Download Hadoop 3.3.6 and place it under the user `hadoop`.

```bash
sudo tar -xvf hadoop-3.3.6.tar.gz
sudo mv hadoop-3.3.6 /usr/local/hadoop
```

#### Configure Hadoop Environment
Edit the `.bashrc` file to set up environment variables.
```bash
nano ~/.bashrc
```
Add the following:
```bash
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
```
Apply the changes:
```bash
source ~/.bashrc
```

#### Configure Hadoop XML Files

1. **`core-site.xml`**:
```bash
sudo nano $HADOOP_HOME/etc/hadoop/core-site.xml
```
Add the following:
```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
```

2. **`hdfs-site.xml`**:
```bash
sudo nano $HADOOP_HOME/etc/hadoop/hdfs-site.xml
```
Add the following:
```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///usr/local/hadoop/tmp/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///usr/local/hadoop/tmp/dfs/data</value>
    </property>
</configuration>
```

3. **`mapred-site.xml`**:
```bash
sudo nano $HADOOP_HOME/etc/hadoop/mapred-site.xml
```
Add the following:
```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

4. **`yarn-site.xml`**:
```bash
sudo nano $HADOOP_HOME/etc/hadoop/yarn-site.xml
```
Add the following:
```xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>
```

#### Configure Java Home
Get the Java home path:
```bash
readlink -f /bin/java
```
Then edit `.bashrc` again to add Java environment variables:
```bash
nano ~/.bashrc
```
Add the following:
```bash
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.412.b08-1.el7_9.x86_64
export PATH=$PATH:$JAVA_HOME/bin
```
Apply the changes:
```bash
source ~/.bashrc
```

#### Change Ownership of Hadoop Directory
```bash
sudo chown -R hadoop:hadoop /usr/local/hadoop
```

#### Format the NameNode and Start Hadoop
```bash
hdfs namenode -format
start-dfs.sh
```

#### SSH Setup
Generate an SSH key for Hadoop user:
```bash
ssh-keygen -t rsa -P "" -f ~/.ssh/id_rsa
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys
jps
```

---

### 2. Setup Hive

#### Download and Install Hive
- Download Apache Hive 3.1.3 and place it under `/etc/software`.

```bash
sudo tar -xvf apache-hive-3.1.3-bin.tar.gz
sudo mv apache-hive-3.1.3-bin /etc/software
```

#### Configure Hive Environment
Edit the `.bashrc` file to configure the Hive environment.
```bash
nano ~/.bashrc
```
Add the following:
```bash
export HIVE_HOME=/usr/local/hive
export PATH=$PATH:$HIVE_HOME/bin
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
```
Apply the changes:
```bash
source ~/.bashrc
```

#### Setup MySQL for Hive

1. **Remove MariaDB**:
```bash
rpm -qa|grep mariadb
rpm -e --nodeps mariadb-libs
```

2. **Install MySQL**:
```bash
sudo yum install -y wget libaio
sudo rpm -ivh mysql-community-common-9.0.1-1.el7.x86_64.rpm
sudo rpm -ivh mysql-community-client-plugins-9.0.1-1.el7.x86_64.rpm
sudo rpm -ivh mysql-community-libs-9.0.1-1.el7.x86_64.rpm
sudo rpm -ivh mysql-community-client-9.0.1-1.el7.x86_64.rpm
sudo rpm -ivh mysql-community-server-9.0.1-1.el7.x86_64.rpm
```

3. **Initialize MySQL**:
```bash
mysqld --initialize --console
chown -R mysql:mysql /var/lib/mysql/
systemctl start mysqld
```

4. **Set up MySQL User**:
Retrieve the temporary password:
```bash
cat /var/log/mysqld.log|grep localhost
```
Login and change the root password:
```bash
mysql -uroot -p
```
Inside MySQL, run the following:
```sql
ALTER USER 'root'@'localhost' IDENTIFIED BY '123';
CREATE USER 'hadoop'@'localhost' IDENTIFIED BY '123';
GRANT ALL PRIVILEGES ON *.* TO 'hadoop'@'localhost';
FLUSH PRIVILEGES;
exit
```
Enable MySQL at startup:
```bash
systemctl enable mysqld
```

#### Configure Hive with Derby (Optional)
Download Hive 3.1.3, extract, and configure:
```bash
tar -xvf apache-hive-3.1.3-bin.tar.gz
sudo mv apache-hive-3.1.3-bin /usr/local/hive
sudo rm -rf lib/guava-19.0.jar
sudo cp /usr/local/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar ./lib
```

Set up Hive environment:
```bash
cd conf/
sudo mv hive-env.sh.template hive-env.sh
sudo vim hive-env.sh
```
Add the following:
```bash
export HADOOP_HOME=/usr/local/hadoop
export HIVE_CONF_DIR=/usr/local/hive/conf
export HIVE_AUX_JARS_PATH=/usr/local/hive/lib
```

Initialize Hive schema using Derby:
```bash
bin/schematool -dbType derby -initSchema
start-dfs.sh
bin/hive
```

#### Configure Hive with MySQL
1. **Set up MySQL JDBC Connector**:
```bash
unzip mysql-connector-j-5.1.48.zip
sudo mv mysql-connector-j-5.1.48/mysql-connector-j-5.1.48.jar /usr/local/hive/lib/
```

2. **Configure Hive to Use MySQL**:
```bash
sudo vim hive-site.xml
```
Add the following:
```xml
<configuration>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8</value>
        <description>JDBC connect string for a JDBC metastore</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hadoop</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>123</value>
    </property>
    <property>
        <name>hive.metastore.schema.verification</name>
        <value>false</value>
    </property>
    <property

>
        <name>hive.metastore.event.db.notification.api.auth</name>
        <value>false</value>
    </property>
</configuration>
```

3. **Initialize Hive Schema Using MySQL**:
```bash
start-dfs.sh
bin/schematool -initSchema -dbType mysql -verbose
bin/hive
```
