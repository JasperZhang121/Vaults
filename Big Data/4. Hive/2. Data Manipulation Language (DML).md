### Load

The `LOAD` statement loads data from a file into a Hive table.

```sql
LOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2, ...)];
```

**Keywords Explanation**:
- `LOCAL`: Loads data from the local filesystem. Without this keyword, data is loaded from HDFS.
- `OVERWRITE`: Overwrites the existing data in the table. Without this, data is appended to the table.
- `PARTITION`: Specifies the partition to load the data into. If the target is a partitioned table, the partition must be specified.

**Examples**:

1. Create a table:

    ```sql
    CREATE TABLE student (
        id INT,
        name STRING
    )
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY '\t';
    ```

2. Load data from a local file into the Hive table:

    ```sql
    LOAD DATA LOCAL INPATH '/opt/module/datas/student.txt' INTO TABLE student;
    ```

3. Load data from HDFS into the Hive table:
    - Upload the file to HDFS:
      ```shell
      hadoop fs -put /opt/module/datas/student.txt /user/atguigu
      ```
    - Load the HDFS data into the Hive table:
      ```sql
      LOAD DATA INPATH '/user/atguigu/student.txt' INTO TABLE student;
      ```

4. Overwrite existing data in the Hive table:
    - Upload the file to HDFS:
      ```shell
      hadoop fs -put /opt/module/datas/student.txt /user/atguigu;
      ```
    - Overwrite the data in the Hive table:
      ```sql
      LOAD DATA INPATH '/user/atguigu/student.txt' OVERWRITE INTO TABLE student;
      ```

### Insert

#### Insert Query Results into a Table

```sql
INSERT (INTO | OVERWRITE) TABLE tablename [PARTITION (partcol1=val1, partcol2=val2, ...)] select_statement;
```

**Keywords Explanation**:
- `INTO`: Appends the results to the target table.
- `OVERWRITE`: Overwrites the existing data in the target table.

**Examples**:

1. Create a table:

    ```sql
    CREATE TABLE student1 (
        id INT,
        name STRING
    )
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY '\t';
    ```

2. Insert data from a query result:

    ```sql
    INSERT OVERWRITE TABLE student3 SELECT * FROM student;
    ```

#### Insert Given Values into a Table

```sql
INSERT (INTO | OVERWRITE) TABLE tablename [PARTITION (partcol1=val1, partcol2=val2, ...)] VALUES (values_row [, values_row, ...]);
```

**Example**:

```sql
INSERT INTO TABLE student1 VALUES (1, 'wangwu'), (2, 'zhaoliu');
```

#### Write Query Results to a Directory

```sql
INSERT OVERWRITE [LOCAL] DIRECTORY directory
[ROW FORMAT row_format] [STORED AS file_format] select_statement;
```

**Example**:

```sql
INSERT OVERWRITE LOCAL DIRECTORY '/opt/module/datas/student'
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.JsonSerDe'
SELECT id, name FROM student;
```

### Export & Import

The `EXPORT` statement exports table data and metadata to an HDFS path. The `IMPORT` statement imports the exported content back into Hive, restoring both data and metadata. These commands are useful for migrating data between Hive instances.

##### Export

```sql
EXPORT TABLE tablename TO 'export_target_path';
```

##### Import

```sql
IMPORT [EXTERNAL] TABLE new_or_original_tablename FROM 'source_path' [LOCATION 'import_target_path'];
```

**Examples**:

1. Export table data:

    ```shell
    EXPORT TABLE default.student TO '/user/hive/warehouse/export/student';
    ```

2. Import table data:

    ```shell
    IMPORT TABLE student2 FROM '/user/hive/warehouse/export/student';
    ```

### Querying Data

#### Basic Syntax

Refer to the [Hive Language Manual - Select](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select) for detailed information.

```sql
SELECT [ALL | DISTINCT] select_expr, select_expr, ...
FROM table_reference
[WHERE where_condition]
[GROUP BY col_list]
[HAVING col_list]
[ORDER BY col_list]
[CLUSTER BY col_list | [DISTRIBUTE BY col_list] [SORT BY col_list]]
[LIMIT number];
```

#### Relational Operators

##### Basic Syntax

| Operator               | Supported Data Types | Description |
|------------------------|----------------------|-------------|
| A = B                  | Basic Data Types     | Returns `true` if A equals B, otherwise `false`. |
| A <=> B                | Basic Data Types     | Returns `true` if both A and B are `null` or both are not `null`; otherwise, `false`. |
| A <> B, A != B         | Basic Data Types     | Returns `null` if either A or B is `null`; otherwise, `true` if A does not equal B. |
| A < B                  | Basic Data Types     | Returns `null` if either A or B is `null`; otherwise, `true` if A is less than B. |
| A <= B                 | Basic Data Types     | Returns `null` if either A or B is `null`; otherwise, `true` if A is less than or equal to B. |
| A > B                  | Basic Data Types     | Returns `null` if either A or B is `null`; otherwise, `true` if A is greater than B. |
| A >= B                 | Basic Data Types     | Returns `null` if either A or B is `null`; otherwise, `true` if A is greater than or equal to B. |
| A [NOT] BETWEEN B AND C| Basic Data Types     | Returns `null` if any of A, B, or C are `null`. Returns `true` if A is between B and C (inclusive); otherwise, `false`. If `NOT` is used, the result is the opposite. |
| A IS NULL              | All Data Types       | Returns `true` if A is `null`; otherwise, `false`. |
| A IS NOT NULL          | All Data Types       | Returns `true` if A is not `null`; otherwise, `false`. |
| A IN (value1, value2)  | All Data Types       | Returns `true` if A is in the list of values; otherwise, `false`. |
| A [NOT] LIKE B         | String Types         | B is a simple SQL regular expression. Returns `true` if A matches B; otherwise, `false`. For example, 'x%' means A must start with 'x', '%x' means A must end with 'x', and '%x%' means A must contain 'x'. Using `NOT` reverses the result. |
| A RLIKE B, A REGEXP B  | String Types         | B is a Java regular expression. Returns `true` if A matches B; otherwise, `false`. The entire string A must match the regular expression B. |

#### Sorting

##### Global Sorting (Order By)

- `ORDER BY`: Performs global sorting, resulting in only one reducer.
  - `ASC` (ascending, default)
  - `DESC` (descending)
- The `ORDER BY` clause appears at the end of the `SELECT` statement.

##### Sort By (Per Reducer Internal Sorting)

- `SORT BY`: More efficient for large datasets. It does not require global sorting.
- Each reducer produces a sorted file, but the global result is not fully sorted.

##### Distribute By (Partitioning)

- `DISTRIBUTE BY`: Controls which rows go to which reducer, similar to custom partitioning in MapReduce. Useful for subsequent aggregation operations.
- Ensure multiple reducers are assigned to see the effect of `DISTRIBUTE BY`.

##### Cluster By (Partitioning and Sorting)

- `CLUSTER BY`: Combines `DISTRIBUTE BY` and `SORT BY` for the same column. It partitions and sorts data but only supports ascending order.
