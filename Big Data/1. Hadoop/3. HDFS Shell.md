### General Syntax
The general syntax for Hadoop shell commands is:
```
hadoop fs [options] [command] [path]
```
Where:
- `hadoop` is the command to run Hadoop.
- `fs` specifies that the command is related to the file system.
- `[options]` are global options applied to Hadoop commands.
- `[command]` is the specific action you want to perform.
- `[path]` is the HDFS path where the command will be applied.

### Common Hadoop File System Commands

#### 1. `ls`
- **Description**: Lists files and directories in the specified directory.
- **Syntax**: `hadoop fs -ls [path]`

#### 2. `mkdir`
- **Description**: Creates a directory in the specified location.
- **Syntax**: `hadoop fs -mkdir [path]`

#### 3. `rm`
- **Description**: Deletes files or directories.
- **Syntax**: `hadoop fs -rm [path]`
- **Options**: `-r` for recursive deletion of directories.

#### 4. `rmdir`
- **Description**: Removes directories if they are empty.
- **Syntax**: `hadoop fs -rmdir [path]`

#### 5. `cp`
- **Description**: Copies files or directories from source to destination.
- **Syntax**: `hadoop fs -cp [source] [destination]`

#### 6. `mv`
- **Description**: Moves files or directories from source to destination.
- **Syntax**: `hadoop fs -mv [source] [destination]`

#### 7. `put`
- **Description**: Copies files from the local file system to HDFS.
- **Syntax**: `hadoop fs -put [local_path] [hdfs_path]`

#### 8. `get`
- **Description**: Copies files from HDFS to the local file system.
- **Syntax**: `hadoop fs -get [hdfs_path] [local_path]`
- **Options**: `-ignoreCrc` to ignore CRC checks.

#### 9. `cat`
- **Description**: Displays the contents of files.
- **Syntax**: `hadoop fs -cat [path]`

#### 10. `chmod`
- **Description**: Changes the permissions of a file.
- **Syntax**: `hadoop fs -chmod [permissions] [path]`

#### 11. `chown`
- **Description**: Changes the owner of files or directories.
- **Syntax**: `hadoop fs -chown [owner][:group] [path]`

#### 12. `du`
- **Description**: Displays the size of files and directories.
- **Syntax**: `hadoop fs -du [path]`

#### 13. `dus`
- **Description**: Displays a summary of file sizes.
- **Syntax**: `hadoop fs -dus [path]`

#### 14. `count`
- **Description**: Counts the number of directories, files, and bytes under the paths that match the specified file pattern.
- **Syntax**: `hadoop fs -count [path]`

#### 15. `tail`
- **Description**: Displays the last kilobyte of the file to stdout.
- **Syntax**: `hadoop fs -tail [path]`

### Tips
- Always specify the full HDFS path when operating on files or directories.
- Use the `-R` option for recursive operations when applicable.
- Be cautious with the `rm` command, especially with the `-r` option, as it will delete files and directories recursively without confirmation.
- Utilize `put` and `get` commands for data ingestion and extraction between the local file system and HDFS.
- Regularly check the size and count of files in HDFS using `du` and `count` 

---

### Hadoop Startup and Shutdown Scripts

- **`start-dfs.sh` and `stop-dfs.sh`**
  - **Description**: Start and stop the Hadoop Distributed File System (HDFS) daemons, respectively. This includes the NameNode, SecondaryNameNode, and DataNodes.
  - **Usage**: Run these scripts from the Hadoop sbin directory to start or stop the HDFS services.

- **`start-yarn.sh` and `stop-yarn.sh`**
  - **Description**: Start and stop the YARN (Yet Another Resource Negotiator) resource management daemons, respectively. This includes the ResourceManager and NodeManagers.
  - **Usage**: Run these scripts from the Hadoop sbin directory to start or stop YARN services.

### Cluster Management and Maintenance Scripts

- **`hdfs dfsadmin`**
  - **Description**: A tool for HDFS cluster administration, providing commands to manage HDFS state, such as safemode operations, rebalancing the cluster, and updating node configurations.
  - **Usage**: `hdfs dfsadmin [command]`, where `[command]` is one of the various operations supported by `dfsadmin`.

- **`yarn node -list`**
  - **Description**: Lists all the nodes in the YARN cluster along with their status.
  - **Usage**: Run this command to see the health and status of NodeManagers in the YARN cluster.

- **`mr-jobhistory-daemon.sh`**
  - **Description**: Start or stop the MapReduce JobHistory Server daemon, which provides a history of job executions.
  - **Usage**: `mr-jobhistory-daemon.sh start|stop historyserver`, executed from the Hadoop sbin directory.

### Configuration and Environment Scripts

- **`hadoop-env.sh`**
  - **Description**: A shell script invoked at startup to configure the environment for Hadoop daemons. It sets up variables like Java home, Hadoop options, and other necessary environment variables.
  - **Usage**: This script is not run manually but is sourced by other Hadoop scripts to set up the environment.

- **`hdfs namenode -format`**
  - **Description**: Formats the namespace of the HDFS filesystem. This is typically done when setting up a new Hadoop cluster or when resetting an existing cluster.
  - **Usage**: Run this command before starting the HDFS for the first time or when you want to clear the HDFS data and start anew.

### Other Utility Scripts

- **`hadoop fsck`**
  - **Description**: Used to check the health of the HDFS file system, report problems, and sometimes repair inconsistencies.
  - **Usage**: `hadoop fsck [path] [options]` to check the health of files and directories within HDFS.

- **`hadoop distcp`**
  - **Description**: A tool for copying large amounts of data between HDFS clusters; useful for backups, mirroring, or migrating data.
  - **Usage**: `hadoop distcp [source_path] [destination_path]` to copy data from one location to another within HDFS or across clusters.