### Submitting a Job
   - **Job Preparation**: Prepare a job <mark style="background: #FFB8EBA6;">request describing the specific data needed</mark>, the time range, the data format, and any special data processing requirements.
   1. **Request Database and Table Permissions**: Apply for <mark style="background: #FF5582A6;">permissions for the databases and tables required for the computations</mark>.
   2. **Create Tables**: <mark style="background: #FFB86CA6;">Create process and result tables in Hive</mark> for the computations.

### Creating a Project
   - **Directory Structure**: Set up a <mark style="background: #FFF3A3A6;">directory structure to store and manage data</mark>, allowing for data processing and analysis within this directory. This structure can include multiple subdirectories, each representing a specific dataset or subject area.

### Creating a Workflow
   1. **Upload Resource Files**: Upload resource files used in calculations, such as <mark style="background: #FFB8EBA6;">jar files</mark>. In many big data frameworks like Apache Hadoop and Apache Spark, computations and transformations are often written in Java or Scala. Jar files are Java ARchive files that package compiled Java code, libraries, and resources into a single file. <mark style="background: #FFB86CA6;">These jar files contain the necessary code and dependencies required to perform specific tasks in the workflow</mark>.
   2. **Configure Global Parameters**: Set parameters that might be applied across nodes. <mark style="background: #FFF3A3A6;">Make the workflow general and configurable</mark> by setting global parameters like input data path, output result path, etc., which can be easily adjusted during execution to accommodate different datasets or requirements. (**Example**: location of the input data)
   3. **Create Nodes**: Create task nodes within the workflow. Design multiple task nodes in the workflow designer, with each node representing a specific processing step. Workflows are typically composed of <mark style="background: #BBFABBA6;">several tasks</mark> that need to <mark style="background: #ABF7F7A6;">be executed in a specific order</mark>. By creating individual nodes for each task, you can organize and manage the workflow effectively. Each node can represent steps like data extraction, transformation, aggregation, and loading into a target system.
   4. **Debug Execution**: Execute directly on nodes. Before running the entire workflow, debug to ensure each node executes as expected.

### Configuring Schedule Time
   1. **Schedule Time**: Specify the exact time when the task should start.
   2. **Frequency**: Define the repeat cycle of the task.
   3. **Dependencies**: If the current task depends on the completion of other tasks, set these dependencies to ensure tasks execute in the correct order.
   4. **Timeout Settings**: Set the maximum runtime for the task to prevent it from indefinitely occupying resources.
   5. **Notifications and Reports**: Configure how to notify after task completion (e.g., email, SMS) and how to generate and store execution reports.
   6. **Failure Handling**: Specify actions to take if the task fails, such as retry attempts, wait times, or failure notifications.

### Submitting the Workflow
   1. **Complete Configuration**: Define and configure all necessary task nodes, parameters, dependencies, and scheduling settings in the workflow design tool. This includes specifying each task's execution logic, input/output data, and any required resource files.
   2. **Check and Verify**: Before submission, perform checks and verification to ensure the workflow configuration is correct. Validate parameters, confirm resource file paths, test connections, etc.
   3. **Submit Workflow**: Click the "Submit" button to send the workflow to the "Pending Release" page. This action is similar to code submission in software engineering, indicating the current phase of work is complete and ready to move to the next stage.
   4. **Pending Release Page**: On this page, the workflow waits for further review and scheduling. Administrators or authorized personnel can review the pending workflows, checking for compliance with organizational standards, potential performance issues, and data security requirements.
   5. **Review and Schedule**: Once approved, the workflow can be scheduled for execution. Based on the set scheduling parameters (e.g., execution time, frequency), the workflow will run automatically at the predetermined time.
   6. **Monitoring and Optimization**: After the workflow is published and executed, track its execution status in the monitoring interface. View execution logs, performance metrics, etc. If issues or performance bottlenecks are found, adjust and optimize the workflow before resubmitting.
