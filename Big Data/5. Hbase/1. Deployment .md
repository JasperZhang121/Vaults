### Region Server
The Region Server, implemented by the `HRegionServer` class, is responsible for managing Regions. Its main functions are:
- **Data Operations**: `get`, `put`, `delete`
- **Region Operations**: `splitRegion`, `compactRegion`

### Master
The Master, implemented by the `HMaster` class, manages all Region Servers. Its primary roles include:
- **Table Operations**: `create`, `delete`, `alter`
- **RegionServer Management**: Assign regions to each RegionServer, monitor the status of each RegionServer, perform load balancing, and handle failover.

### Zookeeper
HBase utilizes Zookeeper to ensure high availability of the Master, monitor RegionServers, manage metadata entry points, and maintain cluster configuration.

### HDFS
HDFS provides the underlying data storage services for HBase and supports high availability for HBase.

### HBase Architecture Diagram (Incomplete)

- Master
- Zookeeper
- RegionServer
  - store
    - Region
      - StoreFile
      - StoreFile
  - store
    - Region
      - StoreFile
      - StoreFile
  - store
    - Region
      - StoreFile
      - StoreFile


### HBase Installation and Deployment

#### Normal Deployment of Zookeeper
First, ensure the normal deployment of the Zookeeper cluster and start it:
```bash
[a@hadoop102 zookeeper-3.4.10]$ bin/zkServer.sh start
[a@hadoop103 zookeeper-3.4.10]$ bin/zkServer.sh start
[a@hadoop104 zookeeper-3.4.10]$ bin/zkServer.sh start
```

#### Normal Deployment of Hadoop
Ensure the normal deployment of the Hadoop cluster and start it:
```bash
[a@hadoop102 hadoop-2.7.2]$ sbin/start-dfs.sh
[a@hadoop103 hadoop-2.7.2]$ sbin/start-yarn.sh
```

### Extracting HBase
Extract HBase to the specified directory:
```bash
[a@hadoop102 software]$ tar -zxvf hbase-1.3.1-bin.tar.gz -C /opt/module
```

#### Configuring HBase
Modify the corresponding HBase configuration files.
1. **hbase-env.sh**:
   ```bash
   export JAVA_HOME=/opt/module/jdk1.6.0_144
   export HBASE_MANAGES_ZK=false
   ```
2. **hbase-site.xml**:
   ```xml
   <configuration>
       <property>
           <name>hbase.rootdir</name>
           <value>hdfs://hadoop102:9000/HBase</value>
       </property>
       <property>
           <name>hbase.cluster.distributed</name>
           <value>true</value>
       </property>
       <property>
           <name>hbase.master.port</name>
           <value>16000</value>
       </property>
       <property>
           <name>hbase.zookeeper.quorum</name>
           <value>hadoop102,hadoop103,hadoop104</value>
       </property>
       <property>
           <name>hbase.zookeeper.property.dataDir</name>
           <value>/opt/module/zookeeper-3.4.10/zkData</value>
       </property>
   </configuration>
   ```
3. **regionservers**:
   ```text
   hadoop102
   hadoop103
   hadoop104
   ```
4. **Create symbolic links to Hadoop configuration files in HBase**:
   ```bash
   [a@hadoop102 module]$ ln -s /opt/module/hadoop-2.7.2/etc/hadoop/core-site.xml /opt/module/hbase/conf/core-site.xml
   [a@hadoop102 module]$ ln -s /opt/module/hadoop-2.7.2/etc/hadoop/hdfs-site.xml /opt/module/hbase/conf/hdfs-site.xml
   ```

#### Sending HBase to Other Clusters
```bash
[a@hadoop102 module]$ xsync hbase/
```

#### Starting HBase Services
1. **Start Method 1**:
   ```bash
   [a@hadoop102 hbase]$ bin/hbase-daemon.sh start master
   [a@hadoop102 hbase]$ bin/hbase-daemon.sh start regionserver
   ```
   **Note**: If the nodes' clocks are not synchronized, the regionserver will fail to start and throw a `ClockOutOfSyncException`.

   **Fix**:
   a. Synchronize time services (Refer to the documentation: "Big Data Technology: Hadoop Introduction")
   b. Set a larger value for the `hbase.master.maxclockskew` property:
   ```xml
   <property>
       <name>hbase.master.maxclockskew</name>
       <value>180000</value>
       <description>Time difference of regionserver from master</description>
   </property>
   ```

2. **Start Method 2**:
   ```bash
   [a@hadoop102 hbase]$ bin/start-hbase.sh
   ```
   **Stopping Services**:
   ```bash
   [a@hadoop102 hbase]$ bin/stop-hbase.sh
   ```

#### Viewing the HBase Page
After a successful start, you can access the HBase management page via "host:port", for example:
```text
http://hadoop102:16010
```
