### Spark Deployment Modes

Spark supports various cluster managers, including:

1. **Standalone**:
   
    The standalone mode is Spark's built-in simple cluster manager. It comes with complete services and can be deployed independently to a cluster without relying on any other resource management system. Using Standalone, it is easy to set up a cluster.
    
2. **Hadoop YARN**:
   
    A unified resource management mechanism that can run multiple computing frameworks such as MapReduce (MR), Storm, etc. Depending on the location of the Driver in the cluster, it is divided into `yarn-client` (outside the cluster) and `yarn-cluster` (inside the cluster).
    
3. **Apache Mesos**:
   
    A powerful distributed resource management framework that allows multiple different frameworks, including Yarn, to be deployed on it.
    
4. **Kubernetes (K8S)**:
   
    A containerized deployment environment.

In addition to these general cluster managers, Spark also provides a local cluster deployment mode and a Windows environment for user testing and learning. Since Hadoop YARN is the most commonly used cluster manager in production environments, our focus is on Spark cluster deployment in Hadoop YARN mode.

### YARN Mode Operation Mechanism

#### YARN Cluster Mode

1. Execute a script to submit the task, which actually starts a JVM process of `SparkSubmit`.
2. The main method in the `SparkSubmit` class reflects and calls the main method of `YarnClusterApplication`.
3. `YarnClusterApplication` creates a Yarn client and then sends an execution command to the Yarn server: `bin/java ApplicationMaster`.
4. After receiving the command, the Yarn framework starts the ApplicationMaster on the specified NodeManager (NM).
5. ApplicationMaster starts the Driver thread and executes the user's job.
6. ApplicationMaster registers with the ResourceManager (RM) and requests resources.
7. After obtaining resources, ApplicationMaster sends a command to NodeManager: `bin/java CoarseGrainedExecutorBackend`.
8. The `CoarseGrainedExecutorBackend` process receives the message, communicates with the Driver, registers the started Executor, and then starts the computing object Executor to wait for receiving tasks.
9. The Driver thread continues to execute to complete job scheduling and task execution.
10. The Driver assigns tasks and monitors task execution.

Note: `SparkSubmit`, `ApplicationMaster`, and `CoarseGrainedExecutorBackend` are independent processes; Driver is an independent thread; Executor and YarnClusterApplication are objects.

![[yarnCluster.png]]
#### YARN Client Mode

1. Execute a script to submit the task, which actually starts a JVM process of `SparkSubmit`.
2. The main method in the `SparkSubmit` class reflects and calls the main method of the user code.
3. The Driver thread starts, executes the user's job, and creates `ScheduleBackend`.
4. `YarnClientSchedulerBackend` sends a command to ResourceManager: `bin/java ExecutorLauncher`.
5. After receiving the command, the Yarn framework starts ExecutorLauncher on the specified NodeManager (actually still calling the main method of ApplicationMaster).
6. ApplicationMaster registers with ResourceManager and requests resources.
7. After obtaining resources, ApplicationMaster sends a command to NodeManager: `bin/java CoarseGrainedExecutorBackend`.
8. The `CoarseGrainedExecutorBackend` process receives the message, communicates with the Driver, registers the started Executor, and then starts the computing object Executor to wait for receiving tasks.
9. The Driver assigns tasks and monitors task execution.

Note: `SparkSubmit`, `ApplicationMaster`, and `YarnCoarseGrainedExecutorBackend` are independent processes; Executor and Driver are objects.

![YARN Client](yarnClient.png)

#### Standalone Mode Operation Mechanism

The Standalone cluster has two important components:

1. **Master (ResourceManager)**:
    
    A process responsible for resource scheduling and allocation, as well as monitoring the cluster.
    
2. **Worker (NodeManager)**:
    
    A process that runs on a server in the cluster. It has two main responsibilities: storing partitions of RDDs in its memory and starting other processes and threads (Executors) to perform parallel processing and computation on RDD partitions.

##### Standalone Cluster Mode

In Standalone Cluster mode, after submitting the task, the Master finds a Worker to start the Driver.

1. The Driver registers the application with the Master.
2. The Master allocates resources based on the submit script's requirements and starts Executors on the Worker nodes.
3. After starting, Executors register back to the Driver.
4. After all Executors are registered, the Driver starts executing the main function.
5. When an Action operator is executed, stages are divided, and each stage generates a corresponding TaskSet.
6. Tasks are distributed to each Executor for execution.

##### Standalone Client Mode

In Standalone Client mode, the Driver runs on the local machine where the task is submitted.

1. The Driver registers the application with the Master.
2. The Master allocates resources based on the submit script's requirements and starts Executors on the Worker nodes.
3. After starting, Executors register back to the Driver.
4. After all Executors are registered, the Driver starts executing the main function.
5. When an Action operator is executed, stages are divided, and each stage generates a corresponding TaskSet.
6. Tasks are distributed to each Executor for execution.
