### Overview

The evolution of the communication framework in Spark:

- In the early versions of Spark, Akka was used as the internal communication component.
- In Spark 1.3, the Netty communication framework was introduced to solve the problem of large data transmission during shuffles.
- In Spark 1.6, both Akka and Netty could be configured for use. Netty fully implemented the functions of Akka within Spark.
- In the Spark 2.x series, Akka was abandoned, and Netty was used exclusively.

The Spark 2.x versions use the Netty communication framework as the internal communication component. Spark's new RPC framework, based on Netty, was inspired by Akka's design and is based on the Actor model, as shown in the figure below:

![actor](actor.png)

In the Spark communication framework, each component (Client/Master/Worker) can be considered an independent entity. These entities communicate with each other through messages. The relationship between the components is shown in the diagram below:

![sparkMessage](sparkMessage.png)

Each `Endpoint` (Client/Master/Worker) has one `InBox` and N `OutBoxes` (N >= 1, where N depends on how many other endpoints the current endpoint communicates with; each endpoint it communicates with corresponds to one `OutBox`). Messages received by the endpoint are written into the `InBox`, and messages to be sent are written into the `OutBox` and sent to the `InBox` of the other endpoint.

### Spark Communication Endpoints

- **Driver**:

```scala
class DriverEndpoint extends IsolatedRpcEndpoint
```

- **Executor**:

```scala
class CoarseGrainedExecutorBackend extends IsolatedRpcEndpoint
```

#### Analysis of Spark Communication Architecture

The Spark communication architecture is shown in the diagram below:

![SparkCommunicationArchitecture](SparkCommunicationArchitecture.png)

- **RpcEndpoint**:

    The RPC communication endpoint. Each node (Client/Master/Worker) in Spark is called an RPC endpoint, implementing the `RpcEndpoint` interface. It designs different messages and business logic based on the needs of each endpoint. If it needs to send a message (inquiry), it calls the `Dispatcher`. In Spark, all endpoints have a lifecycle:
    
    - Constructor
    - onStart
    - receive*
    - onStop

- **RpcEnv**:
    
    The RPC context environment that each RPC endpoint runs within is called `RpcEnv`. In the current version of Spark, `NettyRpcEnv` is used.
    
- **Dispatcher**:

    The message dispatcher, responsible for dispatching messages sent from or received by remote RPC endpoints to the appropriate inboxes (or outboxes). If the recipient of the message is the endpoint itself, the message is stored in the inbox; otherwise, it is placed in the outbox.

- **Inbox**:

    The message inbox. Each local `RpcEndpoint` corresponds to one inbox. When the `Dispatcher` inserts a message into the inbox, it adds the corresponding `EndpointData` to the internal `ReceiverQueue`. Additionally, when the `Dispatcher` is created, a separate thread is started to poll the `ReceiverQueue` to consume the inbox messages.

- **RpcEndpointRef**:

    A reference to a remote `RpcEndpoint`. When we need to send a message to a specific `RpcEndpoint`, we typically obtain a reference to that `RpcEndpoint` and send the message through that reference.

- **OutBox**:

    The message outbox. For the current `RpcEndpoint`, each target `RpcEndpoint` corresponds to an outbox. If messages need to be sent to multiple target `RpcEndpoints`, there will be multiple `OutBoxes`. Once a message is placed in the outbox, it is immediately sent out using the `TransportClient`. The process of placing the message in the outbox and sending it is handled within the same thread.

- **RpcAddress**:

    Represents the address of the remote `RpcEndpointRef`, consisting of a host and port.

- **TransportClient**:

    The Netty communication client. Each outbox corresponds to a `TransportClient`, which continuously polls the outbox and, based on the receiver information of the outbox message, requests the corresponding remote `TransportServer`.

- **TransportServer**:

    The Netty communication server. Each `RpcEndpoint` corresponds to a `TransportServer`, which receives remote messages and calls the `Dispatcher` to distribute messages to the appropriate inbox or outbox.

### Spark Task Scheduling Mechanism

In production environments, the deployment mode of a Spark cluster is generally YARN-Cluster mode. For subsequent kernel analysis, we assume the cluster is deployed in YARN-Cluster mode. The Driver thread mainly initializes the `SparkContext` object, prepares the required context for operation, maintains an RPC connection with the `ApplicationMaster`, and requests resources from the `ApplicationMaster`. Meanwhile, it begins scheduling tasks based on user business logic, dispatching tasks to available Executors.

When the ResourceManager returns Container resources to the `ApplicationMaster`, the `ApplicationMaster` attempts to start Executor processes in the corresponding Containers. Once the Executor process is up, it registers back to the Driver. After successful registration, it maintains a heartbeat with the Driver while waiting for the Driver to dispatch tasks. Once the tasks are dispatched and executed, the task status is reported back to the Driver.