### Accumulators
Accumulators are used to aggregate information from Executor variables to the Driver. Variables defined in the Driver program will have a separate copy in each Task on the Executor side. Each Task updates these copies, which are then merged back into the Driver.

#### System Accumulators
```java
val rdd = sc.makeRDD(List(1, 2, 3, 4, 5))
// Declare accumulator
var sum = sc.longAccumulator("sum")
rdd.foreach(num => {
  // Use accumulator
  sum.add(num)
})
// Get accumulator value
println("sum = " + sum.value)
```

#### Custom Accumulators
```java
// Custom accumulator
// 1. Extend AccumulatorV2 and specify the generic types
// 2. Override the abstract methods of the accumulator
class WordCountAccumulator extends AccumulatorV2[String, mutable.Map[String, Long]] {
  var map: mutable.Map[String, Long] = mutable.Map()

  // Check if the accumulator is in its initial state
  override def isZero: Boolean = {
    map.isEmpty
  }

  // Copy the accumulator
  override def copy(): AccumulatorV2[String, mutable.Map[String, Long]] = {
    new WordCountAccumulator
  }

  // Reset the accumulator
  override def reset(): Unit = {
    map.clear()
  }

  // Add data to the accumulator (In)
  override def add(word: String): Unit = {
    // Check if the map contains the word
    // If it does, increment the word count
    // If not, add the word to the map
    map(word) = map.getOrElse(word, 0L) + 1L
  }

  // Merge accumulators
  override def merge(other: AccumulatorV2[String, mutable.Map[String, Long]]): Unit = {
    val map1 = map
    val map2 = other.value
    // Merge two maps
    map = map1.foldLeft(map2) {
      (innerMap, kv) => {
        innerMap(kv._1) = innerMap.getOrElse(kv._1, 0L) + kv._2
        innerMap
      }
    }
  }

  // Return the result of the accumulator (Out)
  override def value: mutable.Map[String, Long] = map
}
```

### Broadcast Variables
Broadcast variables are used to efficiently distribute large objects. They <mark style="background: #BBFABBA6;">send a large read-only value to all worker nodes to be used by one or more Spark operations</mark>. For example, if your application needs to send a large read-only lookup table to all nodes, broadcast variables are useful. Spark will send the variable separately for each task.

#### Basic Programming
```java
val rdd1 = sc.makeRDD(List(("a", 1), ("b", 2), ("c", 3), ("d", 4)), 4)
val list = List(("a", 4), ("b", 5), ("c", 6), ("d", 7))
// Declare broadcast variable
val broadcast: Broadcast[List[(String, Int)]] = sc.broadcast(list)
val resultRDD: RDD[(String, (Int, Int))] = rdd1.map {
  case (key, num) => {
    var num2 = 0
    // Use broadcast variable
    for ((k, v) <- broadcast.value) {
      if (k == key) {
        num2 = v
      }
    }
    (key, (num, num2))
  }
}
```

### Enhanced Explanations:

#### Key Points:
- **Partitions**: Each RDD is split into partitions. Each partition can be processed independently and in parallel.
- **Workers and Executors**: Each worker node runs executors that process the partitions of the RDD. The executors perform the transformations on their local partitions.
- **Driver**: The Driver schedules tasks for the partitions and collects the results after execution.

#### Example Walkthrough (Enhanced):
- **RDD Creation**:
  ```java
  val lines = sc.textFile("hdfs://path/to/textfile.txt")
  ```
  - This creates an `RDD[String]` and automatically partitions it.

- **Transformations**:
  ```java
  val words = lines.flatMap(line => line.split(" "))
  val wordPairs = words.map(word => (word, 1))
  val wordCounts = wordPairs.reduceByKey((a, b) => a + b)
  ```
  - Each transformation is applied to the partitions of the RDD.

- **Action**:
  ```java
  val results = wordCounts.collect()
  ```
  - The `collect()` action triggers execution of transformations.

Assume three worker nodes, each handling one partition:

```
          Driver
        (Main Program)
             |
        SparkContext
             |
      Schedules Tasks
             |
     -------------------
    |        |          |
 Worker 1  Worker 2  Worker 3
 (Executor) (Executor) (Executor)
    |        |          |
Partition 1 Partition 2 Partition 3
    |        |          |
 Tasks to process each partition
    |        |          |
  Processes  Processes  Processes
 Partition 1 Partition 2 Partition 3
    |        |          |
  Local Results  Local Results  Local Results
    |        |          |
 Collects Results from all Partitions
             |
         Final Output
```
