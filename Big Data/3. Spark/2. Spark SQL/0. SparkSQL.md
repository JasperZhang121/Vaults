### Hive and SparkSQL
SparkSQL evolved from Shark, which provided a tool for those familiar with <mark style="background: #FFB8EBA6;">RDBMS but not with MapReduce</mark>, allowing them to get up to speed quickly. Hive was the early SQL-on-Hadoop tool running on Hadoop. However, the extensive I/O operations during MapReduce computations, due to intermediate data being written to disk, significantly lowered performance. To improve SQL-on-Hadoop efficiency, many SQL-on-Hadoop tools emerged, with notable ones being:
- Drill
- Impala
- Shark

Shark, developed at the Berkeley Lab as part of the Spark ecosystem, was based on Hive and improved three modules: memory management, physical plan, and execution. It ran on the Spark engine and offered a performance boost of 10-100 times over Hive.

![[shark.png]]
However, as Spark evolved, Shark's heavy reliance on Hive (such as using Hive's syntax parser and query optimizer) limited the Spark team's goal of integrating all components under one stack. This led to the SparkSQL project, which abandoned Shark's codebase but retained some of its advantages like in-memory columnar storage and Hive compatibility, and redeveloped the SparkSQL code. Freed from Hive's dependencies, SparkSQL improved data compatibility, performance optimization, and component extension, making it highly versatile.

- **Data Compatibility**: SparkSQL is compatible with Hive and can fetch data from RDDs, Parquet files, JSON files, and future versions may support data from RDBMS and NoSQL databases like Cassandra.
- **Performance Optimization**: Besides adopting optimization techniques like in-memory columnar storage and byte-code generation, it will introduce cost models to dynamically evaluate queries for the best physical plan.
- **Component Extension**: SQL syntax parser, analyzer, and optimizer can all be redefined and extended.

On June 1, 2014, Shark and SparkSQL project lead Reynold Xin announced the cessation of Shark development, focusing all resources on SparkSQL. This marked the end of Shark but led to the development of two branches: SparkSQL and Hive on Spark.

SparkSQL, as part of the Spark ecosystem, continued to evolve independently of Hive while maintaining compatibility. Hive on Spark is a development plan where Hive can use Spark as one of its underlying engines, alongside MapReduce and Tez.

For developers, SparkSQL simplifies RDD development, enhances development efficiency, and provides fast execution. SparkSQL introduces two programming abstractions similar to Spark Core's RDD:
- DataFrame
- DataSet

### Features of SparkSQL
- **Easy Integration**: Seamlessly integrates SQL queries with Spark programming.
- **Unified Data Access**: Connects to different data sources using the same method.
- **Hive Compatibility**: Runs SQL or HiveQL directly on existing data warehouses.
- **Standard Data Connection**: Connects via JDBC or ODBC.
