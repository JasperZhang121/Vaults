
#### Definition in GB/T 18391

Metadata is data that <mark style="background: #FFB8EBA6;">defines and describes other data</mark>. This implies that metadata is data itself; when data is used in this specific way, it becomes metadata. <mark style="background: #FF5582A6;">Only in a specific context, for a specific purpose, or from a specific perspective does data become metadata</mark>.

#### Context

The collection of environments, purposes, or perspectives where data is used as metadata is referred to as the "context." In a given context, metadata is "data about data." Since metadata is also data, it can be stored in databases and organized using models. Some models are application-specific, while others are more generic.

#### Metamodels

Models describing metadata are often called metamodels. In this sense, the conceptual model introduced in _GB/T 18391.3_ is a metamodel.

#### Components of Metadata

Metadata includes technical and business processes, data rules and constraints, logical data structures, and physical data structures. It describes:
- **The data itself** (e.g., databases, data elements, data models).
- **The concepts represented by data** (e.g., business processes, application systems, software code, technical infrastructure).
- **The relationships between data and concepts**.

#### Importance of Metadata

Without reliable metadata, organizations would not know:
- What data they possess.
- What the data represents.
- Where the data originates.
- How it flows through systems.
- Who has access to it.  

### Activities

1. **Define a Metadata Strategy**.
2. **Understand Metadata Requirements**:
    - (1) Business needs.
    - (2) Technical needs.
3. **Define Metadata Architecture**:
    - (1) Create metamodels.
    - (2) Apply metadata standards.
    - (3) Manage metadata storage.
4. **Create and Maintain Metadata**:
    - (1) Integrate metadata.
    - (2) Distribute and deliver metadata.
5. **Query, Report, and Analyze Metadata**.

### Business Drivers

1. Improved data credibility through context and quality checks.
2. Increased value of strategic information (e.g., master data) by expanding its use.
3. Enhanced operational efficiency by identifying redundant data and processes.
4. Prevention of outdated or incorrect data usage.
5. Reduced time spent on data research.
6. Improved communication between data users and IT professionals.
7. Accurate impact analysis, reducing project failure risk.
8. Shortened time-to-market by reducing system development lifecycle time.
9. Lower training costs and reduced impact of employee turnover through comprehensive documentation of data context, history, and origin.
10. Regulatory compliance.

#### Risks of Poor Metadata Management:

1. Redundant data and data management processes.
2. Duplicative and redundant dictionaries, repositories, and other metadata stores.
3. Inconsistent data element definitions and associated misuse risks.
4. Contradictory and conflicting metadata versions, undermining user confidence.
5. Doubts about metadata and data reliability.

### Goals

1. Record and manage a knowledge system of business terms related to data to ensure consistency in understanding and using data content.
2. Collect and integrate metadata from various sources to understand the similarities and differences in data across departments.
3. Ensure the quality, consistency, timeliness, and security of metadata.
4. Provide standard pathways for metadata users to access metadata.
5. Promote or enforce the use of technical metadata standards to facilitate data exchange. 

### Principles

1. **Organizational Commitment**: Manage data as a corporate asset.
2. **Strategy**: Align metadata initiatives with strategic demands and business priorities.
3. **Enterprise Perspective**: Ensure scalability for future growth.
4. **Subtle Influence**: Advocate for the necessity of metadata and its various uses; emphasizing its value encourages business adoption and provides knowledge assistance.
5. **Access**: Ensure employees know how to access and use metadata.
6. **Quality**: Process owners are responsible for metadata quality.
7. **Audit**: Develop, implement, and review metadata standards to simplify integration and usage.
8. **Improvement**: Create feedback mechanisms for users to report outdated or incorrect metadata to the metadata management team.

### Boundary Between Metadata and Non-Metadata

- From a practical standpoint, one person’s metadata could be another person’s data.
- Rather than focusing on theoretical distinctions, prioritize the functions metadata serves, such as:
    - Creating new data
    - Understanding existing data
    - Enabling system interoperability
    - Accessing and sharing data
- Emphasize the source data that meets these needs. _(Example: The NSA’s definition of metadata in phone surveillance highlights differences between metadata and general understanding.)_ 

### Types of Metadata

Metadata is categorized into three main types:

1. **Business Metadata**
2. **Technical Metadata**
3. **Operational Metadata**

In library and information sciences, metadata can further be divided into:

- **Descriptive Metadata**
- **Structural Metadata**
- **Administrative Metadata** 

### Business Metadata

Focuses on the content and conditions of data, including detailed information related to data governance. Examples include:

1. Definitions and descriptions of datasets, tables, and fields.
2. Business rules, transformation rules, calculations, and derivations.
3. Data models.
4. Data quality rules and validation results.
5. Data update schedules.
6. Data lineage and traceability.
7. Data standards.
8. Specific systems for recording data elements.
9. Valid value constraints.
10. Contact information for stakeholders (e.g., data owners, data stewards).
11. Security and privacy levels of data.
12. Known data issues.
13. Data usage instructions.

### Technical Metadata

Provides technical details about data, the systems storing it, and the processes of data flow within and between systems. Examples include:

1. Physical database table names and field names.
2. Field attributes.
3. Properties of database objects.
4. Access permissions.
5. CRUD (Create, Read, Update, Delete) rules for data.
6. Physical data models, including table names, keys, and indexes.
7. Relationships between data models and physical assets.
8. Details of ETL (Extract, Transform, Load) jobs.
9. File format schema definitions.
10. Source-to-target mapping documentation.
11. Data lineage documentation, including information about upstream and downstream change impacts.
12. Names and descriptions of programs and applications.
13. Schedules and dependencies for periodic jobs (content updates).
14. Recovery and backup rules.
15. Permissions, groups, and roles for data access.

### Operational Metadata

Operational metadata describes the details of processing and accessing data. Examples include:

1. Execution logs of batch processing programs.
2. Extraction history and results.
3. Scheduling exception handling.
4. Audit, balancing, and control metrics results.
5. Error logs.
6. Access patterns, frequency, and execution time of reports and queries.
7. Maintenance plans and execution details for patches and versions, including the current patch level.
8. Backup details, retention rules, creation dates, and disaster recovery plans.
9. Service Level Agreement (SLA) requirements and provisions.
10. Capacity and usage patterns.
11. Data archiving rules, retention policies, and associated archived files.
12. Data cleansing standards.
13. Data sharing rules and agreements.
14. Roles, responsibilities, and contact information for technical personnel.


### Metadata Types Overview

|**Business Metadata**|**Technical Metadata**|**Operational Metadata**|
|---|---|---|
|1. Definitions and descriptions of datasets, tables, and fields.|Physical database table and field names.|Execution logs of batch processing programs.|
|2. Business rules, transformation rules, formulas, and derivations.|Field attributes.|Extraction history and results.|
|3. Data models.|Database object attributes.|Scheduling exception handling.|
|4. Data quality rules and validation results.|Access permissions.|Audit, balancing, and control metrics results.|
|5. Data update schedules.|CRUD (Create, Read, Update, Delete) rules.|Error logs.|
|6. Data lineage and traceability.|Physical data models, including table names, keys, and indexes.|Access patterns, frequency, and execution time of reports and queries.|
|7. Data standards.|Relationships between data models and physical assets.|Maintenance plans and patch/version execution details.|
|8. Specific systems for recording data elements.|ETL job details.|Backup details, retention policies, and disaster recovery plans.|
|9. Valid value constraints.|File format schema definitions.|SLA requirements and provisions.|
|10. Stakeholder contact information (e.g., data owners, stewards).|Source-to-target mapping documentation.|Capacity and usage patterns.|
|11. Data security/privacy levels.|Data lineage documentation (upstream and downstream impacts).|Data archiving rules and archived files.|
|12. Known data issues.|Program and application names and descriptions.|Data cleansing standards.|
|13. Data usage instructions.|Schedules and dependencies for periodic jobs.|Data sharing rules and agreements.|
|14. Recovery and backup rules.|Roles, responsibilities, and contact information for technical personnel.||
|15. Data access permissions, groups, and roles.|||


### ISO/IEC 11179 Metadata Registry Standards

- Related standards include _GBT 18391 Information Technology Metadata Registry System (MDR)_.


### Metadata for Unstructured Data

- All data has some structure, even if not presented in rows and columns.
- Metadata management is crucial for unstructured data, categorized as:
    1. **Descriptive Metadata**: Directory information, synonym keywords.
    2. **Structural Metadata**: Tags, field structures, specific formats.
    3. **Administrative Metadata**: Sources, update schedules, access permissions, navigation information.
    4. **Bibliographic Metadata**: Library catalog entries.
    5. **Record Metadata**: Retention policies.
    6. **Preservation Metadata**: Storage conditions, archival rules. 


### Creation and Management of Metadata

- <mark style="background: #ABF7F7A6;">Metadata is often a byproduct of application processes, not the final product.</mark>
- Most operational metadata is generated during data processing.
- Business metadata can be reverse-engineered from existing data dictionaries, models, and documentation, though this involves risks.
- Technical and business metadata required for database management can be collected during project work.
- Rarely feasible to create metadata purely for its own sake—definitions require time and skills.
- Well-defined business metadata can be reused across projects, ensuring consistent understanding of business concepts across datasets. 

### Metadata Sources

1. **Metadata Repositories in Applications**: Physical tables storing metadata, often built into modeling tools, BI tools, and other applications.
2. **Business Glossaries**: Store organizational business concepts, terms, definitions, and relationships. Excel is a common format. Business users, data stewards, and technical users all rely on these glossaries, which are dynamic and should not be printed.
3. **Business Intelligence Tools**.
4. **Configuration Management Tools**.
5. **Data Dictionaries**.
6. **Data Integration Tools**: Provide APIs for external metadata repositories to extract lineage information.
7. **Database Management and System Catalogs**: Describe database content, sizes, software versions, deployment states, uptime, and operational metadata attributes.
8. **Data Mapping Management Tools**: Often stored in enterprise-wide Excel files.
9. **Data Quality Tools**.
10. **Dictionaries and Directories**: Contain system, source, and location information for organizational data.
11. **Event Messaging Tools**.
12. **Modeling Tools and Repositories**.
13. **Reference Databases**: Record business value and descriptions of enumerated data types (value domains).
14. **Service Registries**: Store technical information on services and endpoints from an SOA perspective.
15. **Other Metadata Stores**: Event logs, source lists, interfaces, code sets, dictionaries, spatial patterns, and data distribution repositories.

### Business Glossary Attributes

A business glossary should include the following attributes:

1. Term name, definition, abbreviation or short name, and any synonyms.
2. The business department and/or application responsible for managing data related to the term.
3. The name of the person maintaining the term and the last update date.
4. Classification of the term or relationships between classifications (business function associations).
5. Conflicting definitions, nature of issues, and action timelines.
6. Common misunderstandings.
7. Algorithms supporting the definition.
8. Lineage.
9. Official or authoritative data sources supporting the term.

### Metadata Lifecycle

- **Phases**:
    1. Creation and collection.
    2. Storage.
    3. Integration.
    4. Delivery.
    5. Usage.
    6. Control and management. 

### Types of Metadata Architecture

1. **Centralized Metadata Architecture**
    
    - Composed of a single metadata repository containing copies of metadata from various sources.
2. **Distributed Metadata Architecture**
    
    - Maintains a single access point without a persistent repository. A metadata retrieval engine fetches data directly from source systems in response to user requests.
3. **Hybrid Metadata Architecture**
    
    - Metadata is moved from source systems to a centralized repository, but the repository is designed to store only user-added metadata, essential standardized metadata, and metadata added manually.
4. **Bidirectional Metadata Architecture**
    
    - Allows metadata changes at any part of the architecture (source, data integration, user interface) and synchronizes changes back to the original source for feedback. 

### Advantages and Disadvantages of Metadata Architectures

**Centralized Metadata Repository**

- **Advantages**:
    
    1. High availability, independent of source systems.
    2. Faster metadata retrieval due to co-location of repository and query functions.
    3. Resolves database structure issues, unaffected by proprietary system attributes.
    4. Enhances metadata quality through transformations, customizations, or supplementation during extraction.
- **Disadvantages**:
    
    1. Complex processes are needed to quickly synchronize changes from source systems to the repository.
    2. High maintenance costs.
    3. Custom modules or middleware may be required for metadata extraction.
    4. Increased demand on IT staff and software vendors for validating and maintaining custom code.

**Distributed Metadata Architecture**

- **Advantages**:
    
    1. Metadata remains as current and valid as possible, being retrieved directly from source systems.
    2. Distributed queries may improve response and processing efficiency.
    3. Proprietary system metadata requests are limited to query processing, minimizing effort required for implementation and maintenance.
    4. Automated query processing is simpler, requiring minimal manual intervention.
    5. Eliminates batch processing, avoiding metadata replication or synchronization.
- **Disadvantages**:
    
    1. Cannot support user-added or manually inserted metadata due to the lack of a repository.
    2. Requires a unified, standardized presentation of metadata from different systems.
    3. Query functionality depends on source system availability.
    4. Metadata quality entirely depends on source systems. 

**Hybrid Metadata Architecture**

- Combines centralized and distributed architectures. Metadata is retrieved almost in real-time from source systems while being augmented or stored centrally as needed.

**Bidirectional Metadata Architecture**

- Enables metadata changes at any point in the architecture and synchronizes updates back to the original source, enforcing source updates.

### Activities

**Activity 1: Define Metadata Strategy**

- **Steps**:
    1. Launch a metadata strategy plan to define short- and long-term goals, involving key stakeholders.
    2. Conduct interviews with stakeholders to gather foundational knowledge.
    3. Assess existing metadata resources and information architecture. Review system architectures and data models to identify challenges.
    4. Develop future metadata architecture by considering organizational structure, data governance, controlled environments, and technical security.
    5. Create a phased implementation plan, prioritizing deliverables and defining step-by-step methods.

**Activity 2: Understand Metadata Requirements**

- **Components**:
    1. Frequency of metadata attribute updates.
    2. Synchronization timelines after source data changes.
    3. Historical information retention requirements.
    4. Access permissions and interface functionalities.
    5. Storage structure and metadata modeling.
    6. Integration rules and requirements for metadata from different sources.
    7. Operational requirements for metadata updates, including logging and submission processes.
    8. Management roles and responsibilities.
    9. Quality requirements for metadata.
    10. Security requirements for confidential metadata. 

**Activity 3: Define Metadata Architecture**

- **Content**:
    1. **Create Metamodels**: Develop a data model for the metadata repository (metamodel). This can include high-level conceptual models describing system relationships or low-level metamodels detailing attributes and processes.
    2. **Apply Metadata Standards**: Monitor compliance with metadata standards through data governance activities.
    3. **Manage Metadata Storage**: Implement control activities for metadata migration and repository updates, ensuring management, monitoring, reporting, alerting, and logging capabilities. 

### Metadata Repository Control Activities

1. Job scheduling and monitoring.
2. Load statistical analysis.
3. Backup, recovery, archiving, and deletion.
4. Configuration modifications.
5. Performance tuning.
6. Query statistical analysis.
7. Query and report generation.
8. Security management. 

### Metadata Quality Control Activities

1. Quality assurance and quality control.
2. Data update frequency—aligned with schedules.
3. Reporting of missing metadata.
4. Reporting of outdated metadata.

### Metadata Management Activities

1. Load, discover, import, and tag data assets.
2. Record mapping and migration relationships with sources.
3. Versioning records.
4. User interface management.
5. Maintain metadata for connected datasets—supporting NoSQL.
6. Establish connections between data and internal data collection—custom connections and job metadata.
7. Licensing for external data sources and subscription feeds.
8. Enhance metadata with additional details, such as GIS integration.

### Metadata Training Activities

1. Educate and train users and data stewards.
2. Generate and analyze management metrics.
3. Train users on control activities, queries, and reporting. 

### Activity 4: Create and Maintain Metadata

Good metadata is the result of deliberate planning. Key principles for metadata management:

1. **Accountability**: Recognize that metadata is often produced through existing processes (e.g., data modeling, SDLC, business process definitions), and those executing the processes are responsible for metadata quality.
2. **Standards**: Develop, enforce, and audit metadata standards to simplify integration and ensure applicability.
3. **Improvement**: Establish feedback mechanisms so users can notify the metadata management team about inaccurate or outdated metadata.

#### Activity 4-1: Integrate Metadata

Metadata should be collected and integrated across the enterprise, including external sources.

- Metadata repositories should integrate extracted technical metadata with related business, process, and management metadata.

**Scanning Methods for Metadata Repositories**:

1. **Dedicated Interfaces**: Single-step process where a scanning program collects metadata from source systems and directly loads it into the repository using specific loaders.
2. **Semi-Dedicated Interfaces**: Two-step process where a scanning program collects metadata from source systems and outputs it to data files in a specific format, providing a more open architecture.

**Types of Files Generated and Used by Scanning Programs**:

1. **Control Files**: Contain structural information about the data source's data model.
2. **Reuse Files**: Include rules for managing the loading process.
3. **Log Files**: Generated at each stage of the process, capturing logs for every scan or extraction operation.
4. **Temporary and Backup Files**: Used during the process or for audit trails.

#### Activity 4-2: Analyze and Deliver Metadata

Metadata can be delivered to data consumers and applications or tools that need to process it.

**Delivery Mechanisms**:

1. Internal metadata websites with browsing, search, query, reporting, and analysis capabilities.
2. Reports, glossaries, and other documents.
3. Data warehouses, data marts, and BI (Business Intelligence) tools.
4. Modeling and software development tools.
5. Messaging and transactions.
6. Web services and application programming interfaces (APIs).
7. Interfaces for external organizations (e.g., supply chain solutions).

### Activity 5: Query, Report, and Analyze Metadata

Front-end applications should support querying and accessing metadata.

**Key Features**:

- The interface and functionality provided to business users differ from those offered to technical users and developers.
- Business user tools may include:
    1. Change impact analysis for new functionality development.
    2. Data lineage reports for resolving data definition issues in data warehouses and BI projects.

### Metadata Management Tools

- **Metadata Repository**:
    - The metadata repository includes an integration layer and manual update interfaces.
    - Tools that process and utilize metadata are integrated into the metadata repository as metadata sources.

### Metadata Management Methods

1. **Data Lineage and Impact Analysis**:
    
    - Provides information on how data moves between systems.
    - **Implementation State Lineage**: Derived from the current program code.
    - **Design State Lineage**: Described in mapping specification documents.
    - Limitations in creating data lineage depend on the coverage of the metadata management system.
    - Tools in the metadata management system import implementation state lineage and supplement it with details from design state lineage files that cannot be extracted automatically.
    - The process of connecting different parts of data lineage is called "stitching," resulting in a panoramic view of data movement from origin to destination.
    - **Focus Areas for Successful Lineage Discovery**:
        - **Business Focus**: Trace lineage based on business priorities, working backward from the target location to the originating source system.
        - **Technical Focus**: Start from the source system and identify directly related data users, progressing to indirect users until all systems are identified.
2. **Metadata for Big Data Collection**:
    
    - Effective data management in data lakes depends heavily on managing metadata properly.


### Implementation Guidelines

- Build a controlled metadata management environment in incremental steps to reduce organizational risks and facilitate user adoption.
- Use open-source relational database platforms for implementing metadata storage, addressing unforeseen control and interface issues at project initiation.
- Design repository content to be generic, reflecting more than just the source system database design.


### Readiness and Risk Assessment

1. Establish a robust metadata strategy.
2. Make everyone aware of the risks of unmanaged metadata.
3. Conduct a formal maturity assessment of current metadata-related activities.
    - A metadata strategy is part of an overall data governance strategy and the first step toward effective data governance.
    - Metadata assessment should include objective reviews of existing metadata and stakeholder interviews.
    - Deliverables from risk assessment include a metadata strategy and implementation roadmap.


### Impacts of Missing High-Quality Metadata

1. Misjudgments caused by incorrect, incomplete, or unreasonable assumptions or lack of knowledge about data content.
2. Exposure of sensitive data, risking customer or employee privacy, damaging business reputation, and leading to legal disputes.
3. Loss of knowledge when domain experts leave without properly documenting their expertise (implicit knowledge remains unexplicit).


### Organizational Readiness Assessment Solutions

- Conduct a formal maturity assessment of metadata-related activities, including:
    1. Key business data elements.
    2. Available metadata glossaries.
    3. Data lineage, profiling, and quality management processes.
    4. Master data management maturity and other aspects.
- Align assessment results with business priorities to provide a foundation for improving metadata management practices.
- Use formal assessment results to build a business case, gain sponsorship, and secure funding.


### Organizational Change Documentation

- Transitioning from unmanaged to managed environments requires work and standards.
- Start with a pilot case demonstrating significant quality benefits.
- Requires support and involvement from senior management and close cross-functional collaboration.


### Metadata Governance

1. **Process Control**:
    
    - Data management teams define standards and manage metadata lifecycle changes.
    - Integrate metadata strategies into software development lifecycle (SDLC) management.
2. **Metadata Solution Documentation**:
    
    - Publish documentation in the community, including:
        1. Metadata management implementation status.
        2. Source and target metadata storage.
        3. Metadata update schedules.
        4. Retention and versioning information.
        5. Content details.
        6. Quality statements or warnings (e.g., missing values).
        7. Status of systems and other data sources (e.g., content history, deletion, or update flags).
        8. Relevant tools, architectures, and personnel.
        9. Removal or masking strategies for sensitive information and data sources.
3. **Metadata Standards and Guidelines**:
    
    - Provide templates, examples, expected inputs, and training.
    - Rules such as "do not define terms using other terms" and integrity statements.
    - Develop templates for different metadata types, influenced by the chosen metadata solution.
    - Governance responsibility includes continuous monitoring of guidelines' effectiveness and updates.


### Metrics for Metadata Management

1. **Repository Completeness**: Compare ideal and actual coverage.
2. **Management Maturity**: Evaluate using capability maturity models (CMM-DMM).
3. **Dedicated Staffing**: Assess resource commitments.
4. **Metadata Usage**.
5. **Business Term Activities**: Usage, updates, definitions, and coverage.
6. **Master Data Service Compliance**.
7. **Metadata Documentation Quality**: Manual and automated evaluations.
8. **Repository Availability**: Uptime, batch processing, and query processing times.