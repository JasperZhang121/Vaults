### Flink Program Structure

Flink programs are built using two fundamental constructs: **streams** and **transformations**.

- **Streams**: Continuous <mark style="background: #FFB8EBA6;">flows of data records</mark>, which can be finite (batch) or infinite (streaming).
- **Transformations**: Operations that process <mark style="background: #FFF3A3A6;">one or more input streams</mark> to produce one or more output streams.

### Components of a Flink Program

A Flink program consists of the following key components:

- **Source**: Defines the data input. Flink provides various types of sources:
  - **Local collection-based sources**: <mark style="background: #BBFABBA6;">Load data from in-memory collections</mark>.
  - **File-based sources**: Read data from files.
  - **Network socket-based sources**: Consume data from network sockets.
  - **Custom sources**: Integrate with systems like Kafka, RabbitMQ, or user-defined data sources.

- **Transformation**: Operations applied to data streams to <mark style="background: #ABF7F7A6;">process or transform the data</mark>. Common transformations include:
  - `map()`, `flatMap()`, `filter()`, `keyBy()`, `reduce()`, `window()`, `union()`
  - Advanced operations: `window join()`, `split()`, `select()`, etc.

- **Sink**: Defines the data output. Flink supports various sinks, such as:
  - Writing to files or printing to the console.
  - Sending data to sockets.
  - Custom sinks, including Kafka, RabbitMQ, MySQL, Elasticsearch, Cassandra, Hadoop FileSystem, and more.


### Parallel Data Streams in Flink

When a Flink program is executed, it maps to a **Streaming Dataflow**, comprising streams and transformation operators. The dataflow begins with one or more source operators and ends with one or more sink operators.

![[Z-Archive/Pictures/Big Data/flinkOperator.png]]
#### Key Concepts

- **Stream Partitions**: A stream may consist of multiple partitions, allowing parallel processing.
- **Operator Subtasks**: Each operator can have multiple subtasks, running independently in separate threads. Subtasks can be executed on different machines or containers.
- **Parallelism**: 
  - The parallelism of a stream matches the parallelism of the operator generating the stream.
  - Adjusting operator parallelism allows scalable and efficient execution.

#### Data Transmission Modes Between Operators

1. **One-to-One Mode**:
   - Maintains both partitioning and order of elements between connected operators.
   - Example: A connection from a `Source` to a `Map` operator retains element order.

2. **Redistributing Mode**:
   - Alters partitioning of the data. Examples:
     - **`keyBy()`**: Repartitions the stream based on a key's hash value.
     - **`broadcast()`**: Sends all data to all operator subtasks.
     - **`rebalance()`**: Randomly redistributes data across subtasks.


### Task and Operator Chain

In Flink, every operation is implemented as an **operator**. During execution, Flink optimizes operators by merging them into an **operator chain**. An operator chain:

- Represents an execution unit that runs as a single thread on a `TaskManager`.
- Improves efficiency by reducing inter-operator communication overhead.
![[taskOperatorChain.png]]

### Task Scheduling and Execution

The Flink execution process involves the following steps:

1. **Generating the DAG**:
   - Flink converts the program into a **Directed Acyclic Graph (DAG)** of tasks and operators.

2. **Submission to JobManager**:
   - The `JobClient` submits the DAG to the `JobManager`.

3. **Task Scheduling**:
   - The `JobManager` assigns tasks to available `TaskManagers` based on resource availability.

4. **Execution**:
   - Tasks run on `TaskManagers`, exchanging data as needed.

5. **Resource Monitoring**:
   - The `JobManager` monitors `TaskManager` heartbeats to ensure smooth execution and manage resource allocation.

#### Key Components

- **JobClient**:
  - Submits tasks and waits for results if required.
  - Converts user-defined code into an executable dataflow.

- **JobManager**:
  - Handles task scheduling, fault tolerance (via checkpoints), and job coordination.
  - In high-availability setups, one `JobManager` serves as the leader, while others remain on standby.

- **TaskManager**:
  - Executes the assigned tasks in isolated JVM threads.
  - Pre-allocated task slots determine the capacity of each `TaskManager`.

### Task Slots and Slot Sharing

#### Task Slots

- **Definition**: A task slot is a portion of `TaskManager` resources allocated for task execution.
- **Allocation**:
  - The number of slots per `TaskManager` is predefined, dividing its total memory equally among the slots.
  - Example: A `TaskManager` with 3 slots allocates 1/3 of its memory to each slot.
- **Benefits**:
  - Limits the number of concurrent tasks a `TaskManager` can run.
  - Provides resource isolation to prevent tasks from interfering with each other.

#### Slot Sharing

- **Purpose**: Enhances resource efficiency by allowing subtasks of different tasks to share the same slot if they belong to the same job.
- **Advantages**:
  - Optimizes resource utilization by dynamically filling available slots.
  - Example: Slot sharing allows a job with a base parallelism of 2 to utilize 6 subtasks, increasing parallelism and fairness.
