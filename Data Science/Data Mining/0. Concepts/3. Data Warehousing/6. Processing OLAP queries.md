
Data Warehouses contain huge volumes of data, yet aim to answer queries in interactive query time time-frames.

One way to deliver fast response times is to pre-compute all the aggregate measures required, at a much increased storage cost.

Data Warehouses must support efficient cube computation, access methods and query processing techniques.

---

#### Data Cube Materialisation

**Data Cubes**

-   A Data cube can be viewed as a lattice of cuboids where each cuboid represents a choice of group-by attributes.    
-   The <mark style="background: #FF5582A6;">bottom-most cuboid is the base cuboid</mark>
-   The <mark style="background: #FF5582A6;">top-most cuboid (apex) contains only one cell</mark>

![[data cube 1.png]]

-   The 3-D base cuboid represents the answer to queries such as  "_What  are the sales for each city, item and year?"._  It is the <mark style="background: #FF5582A6;">least generalised (most specific) cuboid</mark>.
-   The 2-D  cuboids represent the answer to queries such as  "_What is the sum of sales, grouping by city and item?"._
-   The level-2 1-D cuboids represent the answer to queries such as  _"_What is_ _the sum of sales, grouping by city?"._
-   The  0-D apex cuboid, often denoted **all**,  represents the the answer to "What is the sum of sales?". It is the most generalised (least specific) cuboid.

-   The total number of cuboids for this 3-D data cube is 2^3 = 8.

---

**Compute cube**

This cube may be only conceptual, but it can also be _materialised_ (that is, pre-computed) in full to reduce run-time query processing costs.

It can be generated by a sequence of  SQL group-by queries, one for each cuboid.

In a generalised syntax, the complete data cube above could be defined by the query

_define cube sales_cube - city, item, year: sum(sales in dollars)_

And it could them be fully materialised as all 8 cuboids by

_compute cube sales_cube_

 In extended SQL by

```sql
SELECT city, item, year, SUM(sales in dollars)

FROM SALES

GROUP BY CUBE  (city, item, year)
```

However, <mark style="background: #FFB8EBA6;">the full materialisation can be useful for fast query response times, but very expensive in storage</mark>.

---

The number of cuboids in a data cube with <mark style="background: #FF5582A6;">n dimensions and m levels</mark> for each dimension is given by:

<mark style="background: #FF5582A6;">C = (m+1)^n - 1</mark>

where n is the number of dimensions and m is the number of levels for each dimension.

The reason why there is an <mark style="background: #FF5582A6;">additional "+1</mark>" in the formula for the number of cuboids in a data cube is because of the <mark style="background: #FF5582A6;">inclusion of the base cuboid</mark>, which is the cuboid that contains the <mark style="background: #FF5582A6;">lowest level</mark> of aggregation for each dimension.

For example, consider a data cube with 2 dimensions (i.e., n=2) and 2 levels for each dimension (i.e., m=2). Without the inclusion of the base cuboid, there would be 4 cuboids in total (2 cuboids for each dimension). However, with the base cuboid included, there would be an additional cuboid, bringing the total number of cuboids to 5.

In general, for a data cube with n dimensions and m levels for each dimension, there are (m+1)^n possible combinations of levels for each dimension, including the base cuboid. Hence, the formula for the number of cuboids is (m+1)^n - 1.

---

**Question:**

Consider the  (4D)   cube of _sales_ with dimensions _item x time x location x supplier_  and  the concept hierarchy  along the location dimension of (_offices < cities < countries < regions)_ and the concept hierarchy along the time dimension of (_days < quarters < years_).

![[cuboids cal.png]]

How many cuboids are there in the materialised data cube?

```
T = 2 * 4 * 5 * 2 = 80 
```


---

#### Processing OLAP queries

Precomputing all of a data cube is often prohibitively expensive in storage, and typically large parts of the cubiod are never used.

We can

-   Materialise every (cuboid) (full materialisation),
-   none (no materialisation),
-   or some (partial materialisation)

The latter is the typical choice, but it requires intelligent strategies for run-time query processing.

In general, query processing must

1. **Determine which operations should be performed on the available cuboids**

Transform drill, roll, etc. using corresponding SQL and/or OLAP operations, e.g., dice = selection + projection on a cuboid

2. **Determine which materialised cuboid(s) should be selected for  the OLAP operation** by identifying which _could_ be used,  and choosing the cuboid with the least estimated query processing cost.

Example

Consider _sales_cube [time, item, location]_ with measure _sum(sales_in_dollars)_ with 3 hierarchies

time: (day < month < quarter < year)

item: (item_name < brand < type)

location: (street < city < province_or_state < country)

  

Let the query to be processed be on {brand, province_or_state} with the condition “year = 2017”, and there are 5 materialised cuboids available:

1) {year, item_name, city} 

2) {year, brand, country}

3) {year, brand, province_or_state}

4) {item_name, province_or_state}  where year = 2017

5) {item_name, province_or_state}  

_Which cuboid could be selected to process the query?_

-   **The cuboid must contain at least the dimensions mentioned in the query (or more)**
    -   _Cuboids_ _1,2,3 meet this condition_
    -   **Although if the selection clause in a query is weaker than the selection clause in the cuboid, and the other dimensions in the query are contained in the cuboid, then it can be used**
        -   _This allows cuboid 4 to be used, too, because the dimensions {item_name, province_or_state} mentioned in the query are in the cuboid._

-   **Finer-granularity data cannot be generated from coarser-granularity data (ie higher up the concept hierarchy than the query).**
    -   Cuboid 2 cannot be used because _country_ is more general than _province_or_state_. That leaves 1,3,4 as the only cuboids that _can_ be used.

_Which cuboid  would be best to use for the query?_

-   **Prefer a cuboid at the coarsest granularity of data** 
    -   Cuboid 1 is the finest granularity and should typically not be used. So that leaves 3 and 4.
-   **Prefer a small  cuboid or one with prebuilt efficient indexes**
    -   If there are few _year_ values overall  but there are many _item_name_s for each _brand_ then 3 would be smaller and so a good choice.
    -   On the other hand, if 4 has efficient indexes, it could be the better choice.

---
#### Efficient Cube Materialisation

The major strategies for  precomputing cubes are

(1) **Full Cube materialisation** - possibly using the Multiway method, that computes aggregations simultanously across multiple dimensions.

(2) **Cube shell**:

-   Compute all cuboids with _k_ dimensions or less (for some small _k_, like 3) on the assumption that most investigations only need a few selected dimensions; or  
    
-   Compute _shell fragments_  by pre-computation and and fill them in with run-time computation:  a semi-online strategy

(3) **Iceberg Cube:** The Iceberg is a partial cube that can be built top-down by the _BUC method  or top-down and bottom-up by Star Cubing.


---

The three OLAP server architectures are:

1.  ROLAP (Relational Online Analytical Processing)
    -   Benefit: Utilizes existing relational database systems and can handle large volumes of data.
2.  MOLAP (Multidimensional Online Analytical Processing)
    -   Benefit: Provides faster query response time due to pre-computed aggregations and optimized multidimensional data structures.
3.  HOLAP (Hybrid Online Analytical Processing)
    -   Benefit: Offers a balance between ROLAP and MOLAP by allowing both relational and multidimensional data structures to be used, giving more flexibility in handling data.