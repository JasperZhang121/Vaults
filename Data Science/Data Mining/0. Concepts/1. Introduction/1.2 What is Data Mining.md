Definition: **The process of discovering interesting patterns and knowledge  from large amounts of data.**

**Interesting** patterns are **non-trivial, implicit, previously unknown and potentially useful.**

This can also be described as **building models** of data and **evaluating the models** for usefulness.

**Alternative names:** Knowledge discovery in databases (KDD), knowledge extraction, data analytics, data archaeology, data dredging, information harvesting, business intelligence, machine learning, pattern recognition and more.

----

**Data Mining vs Machine Learning vs Statistics?**

No strict distinction, but indicative of a research or business community. **Machine Learning** as induction, abduction and generalisation is older and arose as a branch of AI in the very early days of computing. **Data mining**  (and KDD) arose from Database research in the early 90s.  Machine learning may aim at more agent-oriented methods such as incremental, active and bio-inspired learning. Data mining is more likely to be batch- and large-data- oriented.  Both schools draw heavily on **Statistics** for data characterisation. Some machine-learning/data-mining techniques also arise in Statistics e.g. Naive Bayes, Decision trees.

Due to the very mixed heritage of data mining techniques, you will see data mining language arising from each of these three discipline areas, with very often different names used for the same or a very similar idea. For example, the very fundamental idea of an atomic chunk of data that contributes to the description of some object of interest is variously called an _attribute_, a _feature_, or a _variable_. This course primarily uses the language in the text, which is primarily derived from a  database background, but as a practicing data miner, you must be able to recognise and interchangeably use the various terms.

----

# KDD Process

The Knowledge Discovery in Databases (KDD) process is a widely-used framework for data mining. It consists of several stages that help in discovering useful knowledge from large amounts of data. The following are the steps involved in the KDD process:

1.  **Data cleaning**: In this stage, the data is preprocessed to remove noise, inconsistent data, and irrelevant attributes.
    
2.  **Data integration**: In this stage, data from multiple sources are combined into a single dataset.
    
3.  **Data selection**: In this stage, a subset of the data is selected for analysis.
    
4.  **Data transformation**: In this stage, data is transformed into a form appropriate for mining. This may involve normalization, aggregation, or other transformations.
    
5.  **Data mining**: In this stage, various data mining techniques are applied to the data to discover patterns, associations, and other insights.
    
6.  **Pattern evaluation**: In this stage, the discovered patterns are evaluated to determine their usefulness and reliability.
    
7.  **Knowledge representation**: In this stage, the discovered patterns are represented in a form that can be easily understood by the user.
    
8.  **Deployment**: In this stage, the knowledge gained from the data is deployed to solve real-world problems.
    

The KDD process is an iterative process, meaning that each stage can be revisited if necessary. It is important to note that the KDD process is not a linear process and that the steps may overlap or occur in a different order.