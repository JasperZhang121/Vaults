### Transforming & Filtering Operators — deep dive

#### Quick cheatsheet

- **`map`**: sync 1→1 transform. Ordering preserved.
    
- **`flatMap`**: async 1→N; **concurrent**, order may shuffle; tune with `(concurrency, prefetch)`.
    
- **`concatMap`**: like `flatMap` but **sequential** per source item; ordering preserved.
    
- **`switchMap`**: only the **latest** inner stream matters; cancels previous.
    
- **`filter`/`take`/`skip`/`distinct`**: select, cap, offset, deduplicate.
    
- **`buffer`**: emits `List<T>` batches; **materializes** items (memory!).
    
- **`window`**: emits `Flux<T>` windows (lazy, streamy alternative to `buffer`).
    
- **`groupBy`**: partitions by key → `GroupedFlux<K,T>`; be mindful of key cardinality.
    
- **`scan`**: running fold (emits intermediate states).
    
- **`reduce`**: final fold (emits once at end).
    
- **`collectList`/`collectMap`**: aggregate into collections (return **Mono**).
    

---

### The “transform” family: `map` vs `flatMap` vs `concatMap` vs `switchMap`

```java
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;
import java.time.Duration;

// Pretend this is an async I/O call:
Mono<String> fetchProfile(String user) {
  return Mono.just("profile:" + user).delayElement(Duration.ofMillis(50));
}

Flux<String> users = Flux.just("ann","bob","cy");

// 1) map — sync, cheap, preserves order
users.map(String::toUpperCase)
     .subscribe(System.out::println);

// 2) flatMap — async, concurrent, order may interleave
users.flatMap(this::fetchProfile)            // default concurrency, can interleave
     .subscribe(System.out::println);

// 3) concatMap — async but sequential, preserves order
users.concatMap(this::fetchProfile)
     .subscribe(System.out::println);

// 4) switchMap — only the latest matters (cancels earlier)
Flux<String> typeAhead = Flux.just("a","an","ann").delayElements(Duration.ofMillis(30));
typeAhead.switchMap(this::fetchProfile)      // only "ann" will likely survive
         .subscribe(System.out::println);
```

**Tuning `flatMap`:** `flatMap(fn, concurrency, prefetch)` bounds in-flight work and upstream pressure.

```java
users.flatMap(this::fetchProfile, /*concurrency*/ 64, /*prefetch*/ 32)
     .subscribe();
```

> Rule of thumb
> 
> - Use **`map`** for pure CPU transforms.
>     
> - Use **`flatMap`** for parallel async I/O; bound **concurrency/prefetch**.
>     
> - Use **`concatMap`** when **ordering is required**.
>     
> - Use **`switchMap`** for “live search / last one wins”.
>     

---

### Selection operators: `filter`, `take`, `skip`, `distinct`*

```java
Flux.range(1,10)
    .filter(i -> i % 2 == 0)   // keep evens
    .take(3)                   // take first 3 evens
    .skip(1)                   // drop the first of those 3
    .distinct()                // remove duplicates (may track seen items)
    .subscribe(System.out::println); // prints: 6, 8
```

Useful variants:

- `takeWhile`, `skipWhile` for predicate-based slicing.
    
- `distinctUntilChanged` (does **not** need global memory; only compares to last).
    

---

### Batching vs streaming windows: `buffer` vs `window`

```java
import java.time.Duration;

// 1) buffer — materializes items into List<T> (memory)
Flux.range(1,10)
    .buffer(3)   // [1,2,3], [4,5,6], [7,8,9], [10]
    .subscribe(batch -> System.out.println("batch: " + batch));

// With time:
Flux.interval(Duration.ofMillis(50))
    .take(10)
    .bufferTimeout(5, Duration.ofMillis(120)) // size OR time, whichever first
    .subscribe(b -> System.out.println("buffered: " + b));

// 2) window — emits Flux<T> windows (streamy)
Flux.range(1,10)
    .window(3) // Flux<Flux<Integer>>
    .flatMap(win -> win.reduce(0, Integer::sum)) // sum per window
    .subscribe(System.out::println); // 6, 15, 24, 10
```

**When to prefer `window`:** when downstream can process incrementally (avoids materializing large lists).

---

### Partitioning: `groupBy`

```java
Flux.range(1,10)
    .groupBy(n -> n % 2 == 0 ? "even" : "odd") // Flux<GroupedFlux<String,Integer>>
    .flatMap(group ->
        group.collectList().map(list -> group.key() + " -> " + list)
    )
    .subscribe(System.out::println);
```

**Caution:** `groupBy` creates **one sub-stream per key** and keeps them alive while upstream is active. For high-cardinality keys (e.g., userId), apply:

- a **bounded lifetime** (time-based grouping then complete),
    
- **aggregation then discard** groups promptly,
    
- or rethink whether you need `groupBy` vs keyed batching.
    

---

### Folding & aggregation: `scan`, `reduce`, `collectList`

```java
Flux<Integer> f = Flux.just(1,2,3,4);

// scan — running totals (emits 1,3,6,10)
f.scan(0, Integer::sum).skip(1).subscribe(System.out::println);

// reduce — final total only (emits 10)
f.reduce(0, Integer::sum).subscribe(System.out::println);

// collectList — gather into a List, emits once
f.collectList().subscribe(list -> System.out.println("list: " + list));

// More collectors:
f.collectMap(i -> i % 2 == 0 ? "even" : "odd", i -> i)
 .subscribe(System.out::println); // {odd=3, even=4} — last write wins
```

**Guideline:** `collectList`/`collectMap` can **explode memory** on large/unknown streams. Prefer streaming reductions (`scan` + windowing) or bounded batches.

---

### Worked example (with line-by-line reasoning)

```java
import reactor.core.publisher.Flux;

Flux.range(1,10)
    .filter(i -> i % 2 == 0)                 // keep evens: 2,4,6,8,10
    .map(i -> i * i)                         // squares: 4,16,36,64,100
    .buffer(3)                               // [4,16,36], [64,100]
    .flatMap(list -> Flux.fromIterable(list))// flatten batches back to Flux
    .subscribe(System.out::println);         // 4,16,36,64,100
```

- `filter` narrows the stream early (cheap).
    
- `map` is pure and keeps order.
    
- `buffer(3)` forms **materialized** batches; consider `window(3)` if lists could be large.
    
- `flatMap(Flux::fromIterable)` flattens; `concatMapIterable` preserves ordering explicitly.
    

**Alternative without materialization:**

```java
Flux.range(1,10)
    .filter(i -> i % 2 == 0)
    .map(i -> i * i)
    .window(3)                           // Flux<Flux<Integer>>
    .concatMap(win -> win)               // stream windows sequentially
    .subscribe(System.out::println);
```

---

### StepVerifier snippets (operator semantics)

```java
import reactor.test.StepVerifier;
import java.time.Duration;

// concatMap preserves order:
StepVerifier.create(
  Flux.just("a","b","c")
      .concatMap(s -> Mono.just(s).delayElement(Duration.ofMillis(10)))
)
.expectNext("a","b","c")
.expectComplete()
.verify();

// flatMap may interleave:
StepVerifier.create(
  Flux.just("a","b","c")
      .flatMap(s -> Mono.just(s).delayElement(Duration.ofMillis(10)))
)
.expectNextCount(3)      // order not guaranteed
.expectComplete()
.verify();

// switchMap drops earlier inners:
StepVerifier.withVirtualTime(() ->
  Flux.just("a","an","ann")
      .delayElements(Duration.ofSeconds(1))
      .switchMap(q -> Mono.just(q + "!").delayElement(Duration.ofSeconds(2)))
)
.thenAwait(Duration.ofSeconds(5))
.expectNext("ann!")      // only latest survives
.expectComplete()
.verify();
```

---

### Backpressure notes (batches & parallelism)

- `flatMap(..., concurrency, prefetch)` bounds **in-flight** inner publishers and upstream **pull**. Default prefetch is **256**.
    
- `buffer(n)` **stores n items** per batch; combine with `limitRate`, `onBackpressureDrop/Latest`, or `bufferTimeout` to avoid OOM.
    
- Prefer `window` + streaming reductions when batch size is unbounded.
    

---

### Common pitfalls & fixes

1. **Unbounded `collectList`/`buffer`** on large streams → memory blow-ups.  
    _Fix:_ `bufferTimeout`, `window` + streaming aggregation, or persist partial results.
    
2. **Using `flatMap` where order matters** → shuffled outputs.  
    _Fix:_ `concatMap` or `flatMapSequential`.
    
3. **`switchMap` cancels useful work** (e.g., background saves).  
    _Fix:_ Use `concatMap` or split flows (don’t switch away from critical tasks).
    
4. **High-cardinality `groupBy`** keeping thousands of groups alive.  
    _Fix:_ cap lifetime, aggregate and complete groups quickly, or avoid grouping.
    
5. **Blocking in `map`/`flatMap`** (e.g., JDBC) on event loop threads.  
    _Fix:_ offload with `subscribeOn(Schedulers.boundedElastic())` at the edge.
    
