### Why it matters
Reactive systems keep small thread pools busy with non-blocking I/O. Without **backpressure** and **rate limiting**, bursts overload downstreams (DBs, caches, thirdâ€‘party APIs).

### Tools at your disposal
- **Protocol-level backpressure**: built-in via Reactive Streams demand.
- **Operator-level shaping**: `limitRate`, `sample`, `throttleFirst/Last`, `window`, `buffer(max, onOverflow)`, `onBackpressureDrop/Latest`.
- **Queue isolation**: `flatMap(..., concurrency, prefetch)`, `publishOn(..., prefetch)` to bound in-flight work.
- **External gates**: token buckets, leaky buckets, **rate limiters** (Resilience4j), gateway quotas (Kong/Envoy), or **server-side 429** strategies.

### Bounding concurrency with `flatMap`
```java
Flux<Request> inbound = ...; // e.g., HTTP body or Kafka
Mono<Response> handle(Request r) { return callDownstream(r); }

// Bound concurrency to protect downstream, and limit prefetch to control memory
inbound.flatMap(this::handle, /*concurrency*/ 64, /*prefetch*/ 64)
       .onBackpressureBuffer(10_000, d -> log.warn("overflow: {}", d))
       .subscribe();
```

### Global rate-limit (token bucket) in Reactor (DIY)
```java
import java.time.Duration;
import java.util.concurrent.atomic.AtomicLong;
import reactor.core.publisher.Flux;

class TokenBucket {
  final long capacity, refill;
  final AtomicLong tokens = new AtomicLong();
  TokenBucket(long capacity, long refillPerSecond) {
    this.capacity = capacity; this.refill = refillPerSecond; tokens.set(capacity);
    Flux.interval(Duration.ofSeconds(1)).subscribe(t -> tokens.updateAndGet(x -> Math.min(capacity, x + refill)));
  }
  boolean tryAcquire() { return tokens.getAndUpdate(x -> x>0?x-1:0) > 0; }
}

Flux<Request> flow = ...;
TokenBucket bucket = new TokenBucket(200, 200);

flow.filter(__ -> bucket.tryAcquire())
    .switchIfEmpty(Mono.error(new RuntimeException("rate-limited")))
    .flatMap(this::handle)
    .onErrorResume(ex -> ex.getMessage().contains("rate-limited")
        ? Mono.just(Response.tooManyRequests())
        : Mono.error(ex))
    .subscribe();
```

### Resilience4j RateLimiter (preferred for prod)
```java
import io.github.resilience4j.ratelimiter.RateLimiter;
import io.github.resilience4j.ratelimiter.RateLimiterConfig;
import io.github.resilience4j.reactor.ratelimiter.operator.RateLimiterOperator;

RateLimiterConfig cfg = RateLimiterConfig.custom()
    .timeoutDuration(Duration.ofMillis(50))
    .limitRefreshPeriod(Duration.ofSeconds(1))
    .limitForPeriod(200)
    .build();
RateLimiter rl = RateLimiter.of("downstream", cfg);

Flux<Request> flow = ...;
flow.transformDeferred(RateLimiterOperator.of(rl))
    .flatMap(this::handle)
    .subscribe();
```

### Service-level backpressure: propagate 429/503 with `Retry-After`
- If you cannot accept load, **fail fast** with 429 and include `Retry-After`.
- If **downstream** is overloaded, map to **502/503** and **advertise retry hints**.

### Patterns
- **Shed Load Early**: filter, validate, deduplicate before expensive calls.
- **Coalesce**: batch requests (e.g., `bufferTimeout(100, 10ms)` for DB upserts).
- **Isolate**: critical dependencies in their pools/schedulers.
