In [statistics](https://en.wikipedia.org/wiki/Statistics "Statistics"), the **_k_-nearest neighbors algorithm** (**_k_-NN**) is a [non-parametric](https://en.wikipedia.org/wiki/Non-parametric_statistics "Non-parametric statistics") [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning "Supervised learning") method first developed by [Evelyn Fix](https://en.wikipedia.org/wiki/Evelyn_Fix "Evelyn Fix") and [Joseph Hodges](https://en.wikipedia.org/wiki/Joseph_Lawson_Hodges_Jr. "Joseph Lawson Hodges Jr.") in 1951, and later expanded by [Thomas Cover](https://en.wikipedia.org/wiki/Thomas_M._Cover "Thomas M. Cover"). It is used for [classification](https://en.wikipedia.org/wiki/Statistical_classification "Statistical classification") and [regression](https://en.wikipedia.org/wiki/Regression_analysis "Regression analysis"). In both cases, the input consists of the _k_ closest training examples in a [data set](https://en.wikipedia.org/wiki/Data_set "Data set").

