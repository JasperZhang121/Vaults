
Elastic Net is a linear regression algorithm that combines the properties of both Ridge Regression and Lasso Regression. It adds a penalty term to the least square loss function to handle overfitting problems caused by multicollinearity (correlation between predictors) in the data. It is a linear combination of L1 (Lasso) and L2 (Ridge) penalty terms:

Loss(y, y_pred) = sum((y - y_pred)^2) + α * (1 - λ) * sum(|w|) + α * λ * sum(w^2)

Here, α is the strength of the regularization term and λ is the mixing parameter that determines the proportion of L1 and L2 penalty terms in the loss function. When λ = 0, Elastic Net reduces to Lasso Regression, and when λ = 1, it reduces to Ridge Regression. This combination helps to overcome the limitations of Ridge and Lasso, where Ridge Regression tends to keep all the predictors in the model, and Lasso Regression tends to eliminate some predictors from the model. The optimal value of λ can be determined using cross-validation or using a grid search.

