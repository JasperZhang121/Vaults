Scheduling refers to the process of deciding when a task or process should be executed by the computer. The aim of scheduling is to distribute the available processing time effectively among multiple tasks or processes, with the goal of maximizing the overall performance of the system.

There are several different scheduling algorithms used in computer systems, including:

-   First-Come-First-Served (FCFS)
-   Shortest Job First (SJF)
-   Priority Scheduling
-   Round Robin Scheduling

Each scheduling algorithm has its own advantages and disadvantages and the appropriate algorithm depends on the specific requirements of the system. The operating system determines the order in which processes are executed based on the scheduling algorithm used.

---

## First-Come-First-Served (FCFS)

FCFS is a non-preemptive scheduling algorithm, where the process that arrives first is executed first and so on. This is the simplest scheduling algorithm and doesn't consider any other factors other than the arrival time of the process. The processes are executed in the order they arrive, hence the name "First-Come-First-Served".


## Shortest Job First (SJF)

SJF is a non-preemptive scheduling algorithm, where the process with the shortest burst time is executed first. The idea behind this algorithm is to minimize the average waiting time for the processes. In this algorithm, the CPU is allocated to the process with the shortest burst time, and the process with longer burst time has to wait.


## Priority Scheduling

Priority Scheduling is a preemptive scheduling algorithm, where each process is assigned a priority, and the process with the highest priority is executed first. In case of processes with the same priority, the CPU is allocated to the process that arrived first. The idea behind this algorithm is to minimize the waiting time of high priority processes.


## Round Robin Scheduling

Round Robin Scheduling is a preemptive scheduling algorithm, where the CPU is shared among all processes, and each process is executed for a fixed time slice (time quantum) in a cyclic manner. The time slice is usually set to a small value, such that all processes get a fair share of CPU time. This algorithm is suitable for the scenarios where the processes have a lot of I/O operations.


## <span style="color:yellow">The Multi-Level Feedback Queue</span>

Basic Rules:
- If Priority(A) > Priority(B), A runs (B doesnâ€™t).
- If Priority(A) = Priority(B), A & B run in RR.
- When a job enters the system, it is placed at the highest priority (the topmost queue).
- After some time period S, move all the jobs in the system to the topmost queue.
- After some time period S, move all the jobs in the system to the topmost queue.

<span style="color:yellow">Multiprocessor Scheduling:</span>
Difference between single-CPU hardware and multi-CPU hardware centers around the use of hardware caches, and exactly how data is shared across multiple processors.

Caches are small, fast memories that (in general) hold copies of popular data that is found in the main memory of the system. Main memory, in contrast, holds all of the data, but access to this larger memory is slower. By keeping frequently accessed data in a cache, the system can make the large, slow memory appear to be a fast one.

Caches are thus based on the notion of locality, of which there are two kinds: temporal locality and spatial locality. The idea behind temporal locality is that when a piece of data is accessed, it is likely to be accessed again in the near future; imagine variables or even instructions themselves being accessed over and over again in a loop. The idea behind spatial locality is that if a program accesses a data item at address x, it is likely to access data items near x as well.